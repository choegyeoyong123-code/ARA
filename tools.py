from __future__ import annotations

import csv
import json
import os
import re
import time
from datetime import datetime, timedelta
from typing import Any, Dict, List, Optional, Tuple

import httpx

# =========================
# í™˜ê²½ ë³€ìˆ˜ ì„¤ì • (ìš”ì²­ ë°˜ì˜)
# =========================

ODSAY_API_KEY = os.environ.get("ODSAY_API_KEY") or os.environ.get("ODSAY_KEY")
DATA_GO_KR_SERVICE_KEY = (
    os.environ.get("DATA_GO_KR_SERVICE_KEY")
    or os.environ.get("PUBLIC_DATA_SERVICE_KEY")
    or os.environ.get("SERVICE_KEY")
)

# ìš”ì²­í•˜ì‹  êµì •ë³¸ê³¼ ë™ì¼í•˜ê²Œ ê¸°ë³¸ False ê³ ì •
HTTPX_VERIFY = False

# ë¹„ìš© ìµœì í™”(ê¸°ì¡´ ìš”êµ¬ì‚¬í•­)ìš© ê°„ë‹¨ ìºì‹œ
CACHE_TTL_SECONDS = int(os.environ.get("ARA_CACHE_TTL_SECONDS", "60"))

HEADERS = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
}

# =========================
# ê³µí†µ ìœ í‹¸
# =========================

def _extract_digits(s: str) -> str:
    """ì˜¤íƒ€/ì ‘ë¯¸ì‚¬(190qjs, 190ë²ˆ ë“±)ì—ì„œ ìˆ«ìë§Œ ì¶”ì¶œ"""
    if not s:
        return ""
    return "".join(re.findall(r"\d+", str(s)))

def _safe_get(d: Any, *keys: str, default: Any = None) -> Any:
    cur = d
    for k in keys:
        if not isinstance(cur, dict):
            return default
        cur = cur.get(k)
    return default if cur is None else cur

_CACHE: Dict[str, Tuple[float, Any]] = {}

def _make_cache_key(prefix: str, url: str, params: Dict[str, Any]) -> str:
    frozen = tuple(sorted((k, str(v)) for k, v in (params or {}).items()))
    return f"{prefix}:{url}:{frozen}"

def _cache_get(key: str) -> Optional[Any]:
    now = time.time()
    item = _CACHE.get(key)
    if not item:
        return None
    ts, value = item
    if now - ts > CACHE_TTL_SECONDS:
        _CACHE.pop(key, None)
        return None
    return value

def _cache_set(key: str, value: Any) -> None:
    _CACHE[key] = (time.time(), value)

async def _http_get_json(url: str, params: Dict[str, Any], timeout: float = 10.0) -> Dict[str, Any]:
    cache_key = _make_cache_key("GETJSON", url, params)
    cached = _cache_get(cache_key)
    if cached is not None:
        return {"status": "success", "data": cached, "cached": True}

    try:
        async with httpx.AsyncClient(verify=HTTPX_VERIFY, headers=HEADERS) as client:
            res = await client.get(url, params=params, timeout=timeout)
        res.raise_for_status()
        data = res.json()
        _cache_set(cache_key, data)
        return {"status": "success", "data": data, "cached": False}
    except Exception as e:
        return {"status": "error", "msg": str(e)}

# =========================
# 1) ë‚ ì”¨ ì •ë³´ ì‹¤ì‹œê°„ ì—°ë™ (ê¸°ìƒì²­ API) â€” ìš”ì²­ êµì •ë³¸ ë°˜ì˜
# =========================

async def get_kmou_weather():
    """í•œêµ­í•´ì–‘ëŒ€(ì˜ë„êµ¬ ë™ì‚¼ë™) ì‹¤ì‹œê°„ ê¸°ìƒ ì‹¤í™© ì¡°íšŒ"""
    if not DATA_GO_KR_SERVICE_KEY:
        return json.dumps({"status": "error", "msg": "ê¸°ìƒì²­ API í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤."}, ensure_ascii=False)

    url = "http://apis.data.go.kr/1360000/VilageFcstInfoService_2.0/getUltraSrtNcst"
    now = datetime.now()
    base_date = now.strftime("%Y%m%d")
    base_time_primary = now.strftime("%H00") if now.minute < 35 else now.strftime("%H30")

    # ì•ˆì •ì„±: ê¸°ë³¸ êµì • ë¡œì§(00/30) + ì‹¤íŒ¨ ì‹œ ì „ ì‹œê°(HH00) fallback
    candidates: List[Tuple[str, str]] = [(base_date, base_time_primary)]
    if base_time_primary.endswith("30"):
        candidates.append((base_date, now.strftime("%H00")))
    # ì „ 1ì‹œê°„ HH00 fallback
    prev = now - timedelta(hours=1)
    candidates.append((prev.strftime("%Y%m%d"), prev.strftime("%H00")))

    last_error: Optional[str] = None
    for cand_date, cand_time in candidates:
        params = {
            "serviceKey": DATA_GO_KR_SERVICE_KEY,
            "pageNo": "1",
            "numOfRows": "10",
            "dataType": "JSON",
            "base_date": cand_date,
            "base_time": cand_time,
            "nx": "98",
            "ny": "75",
        }

        try:
            async with httpx.AsyncClient(verify=HTTPX_VERIFY, headers=HEADERS) as client:
                res = await client.get(url, params=params, timeout=10.0)
                data = res.json()

            # ì‘ë‹µ êµ¬ì¡° fail-safe
            code = _safe_get(data, "response", "header", "resultCode", default=None)
            if code and code not in {"00", "0"}:
                last_error = _safe_get(data, "response", "header", "resultMsg", default="API ì˜¤ë¥˜")
                continue

            items = _safe_get(data, "response", "body", "items", "item", default=[])
            if not isinstance(items, list) or not items:
                last_error = "ë‚ ì”¨ raw dataê°€ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤."
                continue

            weather_info: Dict[str, Any] = {}
            for item in items:
                if item.get("category") == "T1H":
                    weather_info["temp"] = item.get("obsrValue")
                if item.get("category") == "PTY":
                    weather_info["state"] = item.get("obsrValue")

            return json.dumps(
                {
                    "status": "success",
                    "weather": {
                        "temp": f"{weather_info.get('temp', 'N/A')}Â°C",
                        "location": "ì˜ë„êµ¬ ë™ì‚¼ë™(í•´ì–‘ëŒ€)",
                        "date": cand_date,
                        "time": cand_time,
                        # raw data ì¼ë¶€ë¥¼ í•¨ê»˜ í¬í•¨(ìˆ«ì ê·¼ê±° ì œê³µ)
                        "raw": weather_info,
                    },
                },
                ensure_ascii=False,
            )
        except Exception as e:
            last_error = str(e)
            continue

    return json.dumps({"status": "error", "msg": f"ë‚ ì”¨ ì¡°íšŒ ì‹¤íŒ¨: {last_error or 'unknown'}"}, ensure_ascii=False)

# =========================
# 2) ë²„ìŠ¤ í•„í„°ë§ ë¡œì§ ìµœì í™” (ODsay) â€” ìš”ì²­ êµì •ë³¸ ë°˜ì˜
# =========================

def _norm(s: str) -> str:
    return "".join((s or "").split()).lower()

def _pick_station_id(stations: List[Dict[str, Any]], priority_names: List[str]) -> Optional[str]:
    if not stations:
        return None
    pri_norm = [_norm(p) for p in priority_names]
    for pnorm in pri_norm:
        for st in stations:
            if _norm(st.get("stationName", "")) == pnorm:
                return st.get("stationID")
    for pnorm in pri_norm:
        for st in stations:
            if pnorm and pnorm in _norm(st.get("stationName", "")):
                return st.get("stationID")
    return stations[0].get("stationID")

_OCEAN_VIEW_STOPS: Dict[str, List[Dict[str, Any]]] = {
    "OUT": [
        {
            "label": "êµ¬ë³¸ê´€",
            "query": "í•´ì–‘ëŒ€",
            "priority": ["í•´ì–‘ëŒ€êµ¬ë³¸ê´€", "í•´ì–‘ëŒ€ êµ¬ë³¸ê´€", "Haeyangdae Old Main Bldg", "í•œêµ­í•´ì–‘ëŒ€í•™êµ", "í•œêµ­í•´ì–‘ëŒ€", "í•´ì–‘ëŒ€ì¢…ì "],
        },
        {"label": "ë°©íŒŒì œì…êµ¬", "query": "ë°©íŒŒì œì…êµ¬", "priority": ["ë°©íŒŒì œì…êµ¬", "ë°©íŒŒì œ ì…êµ¬"]},
        {"label": "ìŠ¹ì„ ìƒí™œê´€", "query": "ìŠ¹ì„ ìƒí™œê´€", "priority": ["ìŠ¹ì„ ìƒí™œê´€"]},
    ],
    "IN": [
        {"label": "ìŠ¹ì„ ìƒí™œê´€", "query": "ìŠ¹ì„ ìƒí™œê´€", "priority": ["ìŠ¹ì„ ìƒí™œê´€"]},
        {"label": "ëŒ€í•™ë³¸ë¶€", "query": "ëŒ€í•™ë³¸ë¶€", "priority": ["ëŒ€í•™ë³¸ë¶€"]},
        {
            "label": "êµ¬ë³¸ê´€",
            "query": "í•´ì–‘ëŒ€",
            "priority": ["í•´ì–‘ëŒ€êµ¬ë³¸ê´€", "í•´ì–‘ëŒ€ êµ¬ë³¸ê´€", "Haeyangdae Old Main Bldg", "í•œêµ­í•´ì–‘ëŒ€í•™êµ", "í•œêµ­í•´ì–‘ëŒ€", "í•´ì–‘ëŒ€ì¢…ì "],
        },
    ],
}

async def get_bus_arrival(bus_number: str = None, direction: str = None):
    if not ODSAY_API_KEY:
        return json.dumps({"status": "error", "msg": "ODSAY_API_KEY ë¯¸ì„¤ì •"}, ensure_ascii=False)

    dir_up = (direction or "").strip().upper()
    if dir_up not in {"OUT", "IN"}:
        return json.dumps(
            {
                "status": "need_direction",
                "msg": "ë²„ìŠ¤ ë™ì„ ì„ ì„ íƒí•´ ì£¼ì„¸ìš”: OUT(ì§„ì¶œ) ë˜ëŠ” IN(ì§„ì…).",
                "ocean_view": {"OUT": ["êµ¬ë³¸ê´€", "ë°©íŒŒì œì…êµ¬", "ìŠ¹ì„ ìƒí™œê´€"], "IN": ["ìŠ¹ì„ ìƒí™œê´€", "ëŒ€í•™ë³¸ë¶€", "êµ¬ë³¸ê´€"]},
            },
            ensure_ascii=False,
        )

    # ìš”ì²­ êµì •ë³¸: ê¸°ë³¸ê°’ 190
    target_bus_num = _extract_digits(bus_number) if bus_number else "190"

    search_url = "https://api.odsay.com/v1/api/searchStation"
    realtime_url = "https://api.odsay.com/v1/api/realtimeStation"

    stops_result: List[Dict[str, Any]] = []
    any_arrivals = False
    any_unfiltered = False
    suggestions: List[Dict[str, Any]] = []

    for stop in _OCEAN_VIEW_STOPS[dir_up]:
        search_res = await _http_get_json(
            search_url,
            {"apiKey": ODSAY_API_KEY, "stationName": stop["query"], "CID": "6"},
            timeout=10.0,
        )
        if search_res["status"] != "success":
            stops_result.append({"label": stop["label"], "status": "error", "msg": search_res.get("msg", "ì •ë¥˜ì¥ ê²€ìƒ‰ ì‹¤íŒ¨")})
            continue

        stations = _safe_get(search_res, "data", "result", "station", default=[]) or []
        station_id = _pick_station_id(stations, stop["priority"])
        if not station_id:
            stops_result.append({"label": stop["label"], "status": "station_not_found", "msg": "ì •ë¥˜ì¥ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."})
            continue

        arr_res = await _http_get_json(realtime_url, {"apiKey": ODSAY_API_KEY, "stationID": station_id}, timeout=10.0)
        if arr_res["status"] != "success":
            stops_result.append({"label": stop["label"], "station_id": station_id, "status": "error", "msg": arr_res.get("msg", "ë„ì°© ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨")})
            continue

        arrival_list = _safe_get(arr_res, "data", "result", "realtimeArrivalList", default=[]) or []
        unfiltered_buses: List[Dict[str, Any]] = []
        filtered_buses: List[Dict[str, Any]] = []

        for bus in arrival_list:
            route_name = bus.get("routeNm", "")
            entry = {
                "bus_no": route_name,
                "status": _safe_get(bus, "arrival1", "msg1", default="ì •ë³´ì—†ìŒ"),
                "low_plate": "ì €ìƒ" if str(bus.get("lowPlate1")) == "1" else "ì¼ë°˜",
            }
            unfiltered_buses.append(entry)

            # ìš”ì²­ êµì •ë³¸: ìˆ«ìë§Œ ì¶”ì¶œí•´ contains ë¹„êµ
            route_digits = _extract_digits(route_name)
            if target_bus_num and target_bus_num not in route_digits:
                continue
            filtered_buses.append(entry)

        if unfiltered_buses:
            any_unfiltered = True
        if filtered_buses:
            any_arrivals = True

        if not filtered_buses and unfiltered_buses:
            suggestions.append({"label": stop["label"], "buses": unfiltered_buses[:3]})

        stops_result.append(
            {
                "label": stop["label"],
                "station_id": station_id,
                "status": "success",
                "buses": filtered_buses[:5],
            }
        )

    if not any_arrivals and any_unfiltered:
        return json.dumps(
            {
                "status": "fallback",
                "direction": dir_up,
                "bus_number": target_bus_num,
                "msg": "ìš”ì²­í•˜ì‹  ë²„ìŠ¤ ë²ˆí˜¸ë¡œëŠ” ë„ì°© ì •ë³´ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ë™ì¼ ì •ë¥˜ì¥ì˜ ê·¼ì ‘ ë„ì°© ì •ë³´ë¥¼ í•¨ê»˜ ì œê³µí•©ë‹ˆë‹¤.",
                "stops": stops_result,
                "suggestions": suggestions,
            },
            ensure_ascii=False,
        )

    if not any_arrivals:
        return json.dumps(
            {
                "status": "empty",
                "direction": dir_up,
                "bus_number": target_bus_num,
                "msg": "í˜„ì¬ ë„ì°© ì •ë³´ë¥¼ í™•ì¸í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤(ë„ì°© ëª©ë¡ì´ ë¹„ì–´ìˆìŒ).",
                "stops": stops_result,
            },
            ensure_ascii=False,
        )

    return json.dumps(
        {"status": "success", "direction": dir_up, "bus_number": target_bus_num, "stops": stops_result},
        ensure_ascii=False,
    )

# =========================
# 3) ë§›ì§‘/ì˜ë£Œ/ì¶•ì œ (ê¸°ì¡´ ê¸°ëŠ¥ ìœ ì§€)
# =========================

def _read_places_csv(limit: int = 5) -> List[Dict[str, str]]:
    path = os.path.join(os.path.dirname(__file__), "places.csv")
    if not os.path.exists(path):
        return []

    rows: List[Dict[str, str]] = []
    with open(path, "r", encoding="utf-8-sig", newline="") as f:
        reader = csv.reader(f)
        for idx, row in enumerate(reader):
            if not row:
                continue
            if idx == 0 and row[0].strip().lower().startswith("git merge"):
                continue
            name = (row[0] if len(row) > 0 else "").strip()
            category = (row[1] if len(row) > 1 else "").strip()
            description = (row[2] if len(row) > 2 else "").strip()
            recommendation = (row[3] if len(row) > 3 else "").strip()
            if not name:
                continue
            rows.append({"name": name, "category": category, "description": description, "recommendation": recommendation})
            if len(rows) >= limit:
                break
    return rows

async def get_cheap_eats(food_type: str = "í•œì‹"):
    """
    ì˜ë„ ì°©í•œê°€ê²©/ê°€ì„±ë¹„ ì‹ë‹¹ ì¡°íšŒ
    - DATA_GO_KR_SERVICE_KEY ì—†ìœ¼ë©´ places.csvë¡œ ì œí•œ ì•ˆë‚´
    """
    if not DATA_GO_KR_SERVICE_KEY:
        places = _read_places_csv(limit=5)
        if not places:
            return json.dumps({"status": "error", "msg": "ê³µê³µë°ì´í„° API í‚¤ ë° ë¡œì»¬ ë°ì´í„°ê°€ ì—†ì–´ ì¡°íšŒí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}, ensure_ascii=False)
        return json.dumps({"status": "success", "source": "local_csv", "restaurants": places}, ensure_ascii=False)

    url = "http://apis.data.go.kr/6260000/GoodPriceStoreService/getGoodPriceStore"
    params = {"serviceKey": DATA_GO_KR_SERVICE_KEY, "numOfRows": "100", "pageNo": "1", "resultType": "json"}
    res = await _http_get_json(url, params, timeout=15.0)
    if res["status"] != "success":
        return json.dumps({"status": "error", "msg": res.get("msg", "API í˜¸ì¶œ ì‹¤íŒ¨")}, ensure_ascii=False)

    try:
        items = _safe_get(res, "data", "getGoodPriceStore", "item", default=[]) or []
        targets = []
        for i in items:
            if "ì˜ë„êµ¬" in (i.get("addr", "") or "") and (food_type in (i.get("induty", "") or "")):
                targets.append(
                    {
                        "name": i.get("sj"),
                        "menu": i.get("menu"),
                        "price": i.get("price"),
                        "tel": i.get("tel"),
                        "addr": i.get("addr"),
                        "desc": i.get("cn", ""),
                    }
                )
        if not targets:
            return json.dumps({"status": "empty", "msg": "ì¡°ê±´ì— ë§ëŠ” ì‹ë‹¹ ì •ë³´ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."}, ensure_ascii=False)
        return json.dumps({"status": "success", "source": "public_api", "restaurants": targets[:5]}, ensure_ascii=False)
    except Exception as e:
        return json.dumps({"status": "error", "msg": str(e)}, ensure_ascii=False)

async def get_medical_info(kind: str = "ì•½êµ­"):
    if not DATA_GO_KR_SERVICE_KEY:
        return json.dumps({"status": "error", "msg": "ê³µê³µë°ì´í„° API í‚¤ê°€ ì—†ì–´ ì¡°íšŒí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}, ensure_ascii=False)

    url = "http://apis.data.go.kr/6260000/MedicInstitService/MedicalInstitInfo"
    params = {"serviceKey": DATA_GO_KR_SERVICE_KEY, "numOfRows": "100", "pageNo": "1", "resultType": "json"}
    res = await _http_get_json(url, params, timeout=15.0)
    if res["status"] != "success":
        return json.dumps({"status": "error", "msg": res.get("msg", "API í˜¸ì¶œ ì‹¤íŒ¨")}, ensure_ascii=False)

    try:
        items = _safe_get(res, "data", "MedicalInstitInfo", "item", default=[]) or []
        targets = []
        for i in items:
            addr = i.get("addr", "") or ""
            instit_kind = i.get("instit_kind", "") or ""
            if "ì˜ë„êµ¬" in addr and kind in instit_kind:
                targets.append({"name": i.get("instit_nm"), "tel": i.get("tel"), "addr": addr, "time": i.get("trtm_mon_end")})
        if not targets:
            return json.dumps({"status": "empty", "msg": "ì¡°ê±´ì— ë§ëŠ” ì˜ë£Œ ê¸°ê´€ ì •ë³´ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."}, ensure_ascii=False)
        return json.dumps({"status": "success", "hospitals": targets[:5]}, ensure_ascii=False)
    except Exception as e:
        return json.dumps({"status": "error", "msg": str(e)}, ensure_ascii=False)

async def get_festival_info():
    if not DATA_GO_KR_SERVICE_KEY:
        return json.dumps({"status": "error", "msg": "ê³µê³µë°ì´í„° API í‚¤ê°€ ì—†ì–´ ì¡°íšŒí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}, ensure_ascii=False)

    url = "http://apis.data.go.kr/6260000/FestivalService/getFestivalKr"
    params = {"serviceKey": DATA_GO_KR_SERVICE_KEY, "numOfRows": "10", "pageNo": "1", "resultType": "json"}
    res = await _http_get_json(url, params, timeout=15.0)
    if res["status"] != "success":
        return json.dumps({"status": "error", "msg": res.get("msg", "API í˜¸ì¶œ ì‹¤íŒ¨")}, ensure_ascii=False)

    try:
        items = _safe_get(res, "data", "getFestivalKr", "item", default=[]) or []
        targets = []
        for i in items:
            targets.append({"title": i.get("MAIN_TITLE"), "place": i.get("MAIN_PLACE"), "date": i.get("USAGE_DAY_WEEK_AND_TIME")})
        if not targets:
            return json.dumps({"status": "empty", "msg": "ì¡°íšŒ ê°€ëŠ¥í•œ ì¶•ì œ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤."}, ensure_ascii=False)
        return json.dumps({"status": "success", "festivals": targets[:5]}, ensure_ascii=False)
    except Exception as e:
        return json.dumps({"status": "error", "msg": str(e)}, ensure_ascii=False)

# =========================
# Tool Specification (CRITICAL)
# =========================

TOOLS_SPEC = [
    {
        "type": "function",
        "function": {
            "name": "get_bus_arrival",
            "description": "ğŸšŒ 190ë²ˆ(í•™êµí–‰): '190ë²ˆ ë²„ìŠ¤ IN' / 190ë²ˆ(ì—­Â·ëŒ€êµí–‰): '190ë²ˆ ë²„ìŠ¤ OUT' í˜•íƒœë¡œ ë²„ìŠ¤ ë„ì°© ì •ë³´ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤.",
            "parameters": {
                "type": "object",
                "properties": {
                    "bus_number": {"type": "string", "description": "ì˜ˆ: 190, 101 ë“±(ë¯¸ì…ë ¥ ì‹œ 190 ê¸°ë³¸ê°’)"},
                    "direction": {"type": "string", "enum": ["IN", "OUT"], "description": "IN(ì§„ì…) ë˜ëŠ” OUT(ì§„ì¶œ)"},
                },
                "required": ["direction"],
            },
        },
    },
    {
        "type": "function",
        "function": {
            "name": "get_kmou_weather",
            "description": "ğŸŒ¤ï¸ í•´ì–‘ëŒ€ ë‚ ì”¨: 'ì§€ê¸ˆ í•™êµ ë‚ ì”¨ ì–´ë•Œ?' í˜•íƒœë¡œ ì‹¤ì‹œê°„ ê¸°ìƒ ì‹¤í™©ì„ ì¡°íšŒí•©ë‹ˆë‹¤.",
            "parameters": {"type": "object", "properties": {}},
        },
    },
    {
        "type": "function",
        "function": {
            "name": "get_cheap_eats",
            "description": "ğŸš ê°€ì„±ë¹„ ë§›ì§‘: 'ì˜ë„ ì°©í•œê°€ê²© ì‹ë‹¹ ì¶”ì²œí•´ì¤˜' í˜•íƒœë¡œ ì°©í•œê°€ê²©/ê°€ì„±ë¹„ ì‹ë‹¹ì„ ì¶”ì²œí•©ë‹ˆë‹¤.",
            "parameters": {"type": "object", "properties": {"food_type": {"type": "string"}}},
        },
    },
    {
        "type": "function",
        "function": {
            "name": "get_medical_info",
            "description": "ğŸ¥ ì•½êµ­/ë³‘ì›: 'í•™êµ ê·¼ì²˜ ì•½êµ­ì´ë‚˜ ë³‘ì› ì•Œë ¤ì¤˜' í˜•íƒœë¡œ ì˜ë£Œ ê¸°ê´€ ì •ë³´ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤.",
            "parameters": {"type": "object", "properties": {"kind": {"type": "string"}}},
        },
    },
    {
        "type": "function",
        "function": {
            "name": "get_festival_info",
            "description": "ğŸ‰ ì¶•ì œ/í–‰ì‚¬: 'ì§€ê¸ˆ ë¶€ì‚°ì— í•˜ëŠ” ì¶•ì œ ìˆì–´?' í˜•íƒœë¡œ ë¶€ì‚° ì¶•ì œ ì •ë³´ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤.",
            "parameters": {"type": "object", "properties": {}},
        },
    },
]