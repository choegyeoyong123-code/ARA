from __future__ import annotations

import csv
import json
import os
import re
import time
import asyncio
from datetime import datetime, timedelta, date
from typing import Any, Dict, List, Optional, Tuple
from urllib.parse import quote_plus

import httpx
from zoneinfo import ZoneInfo

# =========================
# í™˜ê²½ ë³€ìˆ˜ ì„¤ì • (ìš”ì²­ ë°˜ì˜)
# =========================

ENV_MODE = (os.environ.get("ENV_MODE") or "prod").strip().lower()
# í…ŒìŠ¤íŠ¸/ì‹œë®¬ë ˆì´ì…˜ìš© ê¸°ì¤€ ì‹œê° ì˜¤ë²„ë¼ì´ë“œ(ë¯¸ì„¤ì • ì‹œ ì‹œìŠ¤í…œ ì‹œê° ì‚¬ìš©)
ARA_REF_DATE = (os.environ.get("ARA_REF_DATE") or "").strip()
ARA_REF_TIME = (os.environ.get("ARA_REF_TIME") or "").strip()

ODSAY_API_KEY = os.environ.get("ODSAY_API_KEY") or os.environ.get("ODSAY_KEY")
DATA_GO_KR_SERVICE_KEY = (
    os.environ.get("DATA_GO_KR_SERVICE_KEY")
    or os.environ.get("PUBLIC_DATA_SERVICE_KEY")
    or os.environ.get("SERVICE_KEY")
)

# SSL ë³´ì•ˆ ê°•í™”: ìš´ì˜ ê¸°ë³¸ True, ê°œë°œ(dev)ì—ì„œë§Œ False í—ˆìš©
# - ë¡œì»¬ì—ì„œ ì¸ì¦ì„œ ë¬¸ì œê°€ ë°œìƒí•˜ëŠ” ê²½ìš°ì—ë§Œ dev ëª¨ë“œë¡œ ì‚¬ìš©í•˜ì„¸ìš”.
HTTPX_VERIFY = False if ENV_MODE == "dev" else True

# ë¹„ìš© ìµœì í™”(ê¸°ì¡´ ìš”êµ¬ì‚¬í•­)ìš© ê°„ë‹¨ ìºì‹œ
CACHE_TTL_SECONDS = int(os.environ.get("ARA_CACHE_TTL_SECONDS", "60"))

HEADERS = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
}

# í‘œì¤€ íƒ€ì„ì¡´(KST)
_KST = ZoneInfo("Asia/Seoul")

# =========================
# ARA Signature UI (Theme)
# =========================

THEME_COLOR = "5CABDC"  # Ocean Blue
THEME_TEXT_COLOR = "ffffff"  # White

EMOJI_BUS = "ğŸšŒ"
EMOJI_TIME = "â±ï¸"
EMOJI_WEATHER = "ğŸŒ¤ï¸"
EMOJI_FOOD = "ğŸ±"
EMOJI_UNI = "âš“"

def get_theme_image(text: str) -> str:
    """
    í…Œë§ˆ ë°°ë„ˆ ì´ë¯¸ì§€(ì„ì‹œ): placehold.coë¥¼ ì´ìš©í•´ í”„ë¡œí•„ ì»¬ëŸ¬ ê¸°ë°˜ ë°°ë„ˆ ìƒì„±
    """
    t = (text or "").strip()
    # URL queryëŠ” ë°˜ë“œì‹œ ì¸ì½”ë”©
    return f"https://placehold.co/800x400/{THEME_COLOR}/{THEME_TEXT_COLOR}?text={quote_plus(t)}&font=roboto"

def _kakao_item_card(
    *,
    thumbnail_text: str,
    head_title: str,
    head_desc: str,
    items: List[Tuple[str, str]],
    buttons: List[Dict[str, Any]],
) -> Dict[str, Any]:
    """
    Kakao itemCard payload ìƒì„±(ì‹œê·¸ë‹ˆì²˜ UI)
    - ì£¼ì˜: Open Builder ë Œë”ë§ì€ í™˜ê²½ì— ë”°ë¼ ì°¨ì´ê°€ ìˆì„ ìˆ˜ ìˆì–´, ì‹¤íŒ¨ ì‹œ main.pyì—ì„œ basicCardë¡œ í´ë°± ê°€ëŠ¥í•˜ë„ë¡ êµ¬ì„±í•©ë‹ˆë‹¤.
    """
    return {
        "thumbnail": {"imageUrl": get_theme_image(thumbnail_text)},
        "imageTitle": {"title": (head_title or "")[:50], "description": (head_desc or "")[:100]},
        "itemList": [{"title": (t or "")[:20], "description": (d or "")[:60]} for (t, d) in (items or [])][:10],
        "buttons": (buttons or [])[:3],
        "buttonLayout": "horizontal",
    }

# =========================
# ê³µí†µ ìœ í‹¸
# =========================

# =========================
# Astronomy (KASI) Rise/Set Time
# =========================

_ASTRO_CACHE_TTL_SECONDS = int(os.environ.get("ARA_ASTRONOMY_CACHE_TTL_SECONDS", "3600"))
_ASTRO_CACHE: Dict[str, Tuple[float, str]] = {}

def _format_hhmm(raw: str) -> Optional[str]:
    """
    '1742' -> '17:42'
    - ìˆ«ì 4ìë¦¬(ë˜ëŠ” 6ìë¦¬)ë§Œ í—ˆìš©
    """
    if not raw:
        return None
    digits = re.sub(r"\D+", "", str(raw))
    if len(digits) == 6:
        digits = digits[:4]
    if len(digits) != 4:
        return None
    hh, mm = digits[:2], digits[2:]
    if not (hh.isdigit() and mm.isdigit()):
        return None
    h, m = int(hh), int(mm)
    if not (0 <= h <= 23 and 0 <= m <= 59):
        return None
    return f"{h:02d}:{m:02d}"

def get_calendar_day_2026(date_yyyymmdd: str):
    """
    2026 ì§„ì‹¤ ì†ŒìŠ¤: calendar_2026.json
    - days[YYYYMMDD]ì— ì €ì¥ëœ ê°’ë§Œ ì‹ ë¢°
    - ì—†ìœ¼ë©´ 'ì—…ë°ì´íŠ¸ ì¤‘'ìœ¼ë¡œ ì²˜ë¦¬(ì ˆëŒ€ ê³„ì‚°/ì¶”ì¸¡ ê¸ˆì§€)
    """
    digits = re.sub(r"\D+", "", str(date_yyyymmdd or ""))
    if len(digits) != 8 or not digits.startswith("2026"):
        return json.dumps({"status": "not_found", "date": digits, "msg": "Data is currently being updated for this specific date."}, ensure_ascii=False)
    path = os.path.join(os.path.dirname(__file__), "calendar_2026.json")
    try:
        with open(path, "r", encoding="utf-8") as f:
            data = json.load(f)
        days = data.get("days") if isinstance(data, dict) else None
        if not isinstance(days, dict):
            return json.dumps({"status": "not_found", "date": digits, "msg": "Data is currently being updated for this specific date."}, ensure_ascii=False)
        day = days.get(digits)
        if not day:
            return json.dumps({"status": "not_found", "date": digits, "msg": "Data is currently being updated for this specific date."}, ensure_ascii=False)
        return json.dumps({"status": "success", "date": digits, "day": day}, ensure_ascii=False)
    except Exception:
        return json.dumps({"status": "not_found", "date": digits, "msg": "Data is currently being updated for this specific date."}, ensure_ascii=False)

def is_holiday_2026(date_yyyymmdd: str) -> Optional[bool]:
    """
    ê³µíœ´ì¼ íŒë‹¨ì€ calendar_2026.jsonë§Œ ì‚¬ìš©(ê³„ì‚° ê¸ˆì§€).
    - day.is_holiday == true/false ê°€ ìˆìœ¼ë©´ ê·¸ ê°’ë§Œ ì‚¬ìš©
    - ì—†ìœ¼ë©´ None(ë¯¸í™•ì¸)
    """
    raw = get_calendar_day_2026(date_yyyymmdd)
    try:
        payload = json.loads(raw) if isinstance(raw, str) else (raw or {})
    except Exception:
        return None
    if not isinstance(payload, dict) or payload.get("status") != "success":
        return None
    day = payload.get("day") or {}
    if isinstance(day, dict) and "is_holiday" in day:
        return bool(day.get("is_holiday"))
    return None

def get_academic_schedule(query: Optional[str] = None, today_yyyy_mm_dd: Optional[str] = None, lang: str = "ko"):
    """
    2026 í•™ì‚¬ì¼ì • D-Day ê³„ì‚°(ì›¹ í¬ë¡¤ë§ ê¸ˆì§€ / í•˜ë“œì½”ë”© ë”•ì…”ë„ˆë¦¬ë§Œ ì‚¬ìš©)
    - ì…ë ¥:
      - query(ì„ íƒ): íŠ¹ì • ì´ë²¤íŠ¸ëª… ê²€ìƒ‰(ë¶€ë¶„ì¼ì¹˜)
      - today_yyyy_mm_dd(ì„ íƒ): í…ŒìŠ¤íŠ¸/ì‹œë®¬ë ˆì´ì…˜ìš© ê¸°ì¤€ì¼(YYYY-MM-DD)
      - lang(ì„ íƒ): ko/en (í˜„ì¬ëŠ” ko ê¸°ì¤€ í…ìŠ¤íŠ¸ ì œê³µ, ë°ì´í„° êµ¬ì¡°ëŠ” ê³µí†µ)
    - ì¶œë ¥: json ë¬¸ìì—´
      - items: [{name, date, weekday_ko, d_day, days_diff}]
    """
    # ìš”êµ¬ì‚¬í•­: í•¨ìˆ˜ ë‚´ë¶€ì— ì •í™•í•œ ë”•ì…”ë„ˆë¦¬ë¥¼ "ë³µì‚¬"í•˜ì—¬ ì‚¬ìš©
    SCHEDULE_2026 = {
        "1í•™ê¸° ìˆ˜ê°•ì‹ ì²­": "2026-02-23",  # Corrected from PDF (Feb 23 is Mon)
        "ì „ê¸° í•™ìœ„ìˆ˜ì—¬ì‹(ì¡¸ì—…)": "2026-02-24",
        "1í•™ê¸° ì¬í•™ìƒ ë“±ë¡ê¸ˆ ë‚©ë¶€": "2026-02-24",
        "2026 ì…í•™ì‹": "2026-02-26",
        "1í•™ê¸° ê°œê°•": "2026-03-02",      # Standard Start Date
        "1í•™ê¸° ìˆ˜ì—…ì¼ìˆ˜ 1/3ì„ ": "2026-04-07",
        "1í•™ê¸° ì¤‘ê°„ê³ ì‚¬(ì˜ˆìƒ)": "2026-04-20", # 8th week estimate
        "ê·¼ë¡œìì˜ ë‚ ": "2026-05-01",
        "ëŒ€ë™ì œ(ì˜ˆìƒ)": "2026-05-20",
        "1í•™ê¸° ê¸°ë§ê³ ì‚¬(ì˜ˆìƒ)": "2026-06-15",
        "ì—¬ë¦„ë°©í•™ ì‹œì‘": "2026-06-22",
        "2í•™ê¸° ê°œê°•": "2026-09-01",
        "ê°œêµê¸°ë…ì¼": "2026-11-05"
    }

    lang = (lang or "ko").strip().lower()
    if lang not in {"ko", "en"}:
        lang = "ko"

    def _parse_ymd(s: str) -> Optional[date]:
        try:
            d = date.fromisoformat((s or "").strip())
            if d.year != 2026:
                return None
            return d
        except Exception:
            return None

    def _weekday_ko(d: date) -> str:
        # ì›”(0)~ì¼(6)
        names = ["ì›”", "í™”", "ìˆ˜", "ëª©", "ê¸ˆ", "í† ", "ì¼"]
        try:
            return names[d.weekday()]
        except Exception:
            return ""

    def _dday_label(days_diff: int) -> str:
        if days_diff == 0:
            return "D-DAY"
        if days_diff > 0:
            return f"D-{days_diff}"
        return f"D+{abs(days_diff)}"

    # ê¸°ì¤€ì¼(KST) ê²°ì •
    if today_yyyy_mm_dd:
        today_date = _parse_ymd(today_yyyy_mm_dd)
        if today_date is None:
            # ì…ë ¥ì´ ì˜ëª»ëœ ê²½ìš°, ì‹œìŠ¤í…œ ê¸°ì¤€ìœ¼ë¡œ í´ë°±
            today_date = _reference_datetime().date()
    else:
        today_date = _reference_datetime().date()

    # ê²€ìƒ‰ì–´ ì •ê·œí™”(ë¶€ë¶„ì¼ì¹˜)
    q = (query or "").strip()
    q_norm = re.sub(r"\s+", "", q)

    items: List[Dict[str, Any]] = []
    for name, ds in SCHEDULE_2026.items():
        if q_norm:
            key_norm = re.sub(r"\s+", "", str(name))
            if (q_norm not in key_norm) and (key_norm not in q_norm):
                continue
        d = _parse_ymd(ds)
        if d is None:
            items.append(
                {
                    "name": name,
                    "date": ds,
                    "weekday_ko": "",
                    "days_diff": None,
                    "d_day": None,
                    "status": "invalid_date",
                }
            )
            continue
        diff = (d - today_date).days
        items.append(
            {
                "name": name,
                "date": d.isoformat(),
                "weekday_ko": _weekday_ko(d),
                "days_diff": diff,
                "d_day": _dday_label(diff),
                "status": ("today" if diff == 0 else ("upcoming" if diff > 0 else "past")),
            }
        )

    # ë‚ ì§œ ê¸°ì¤€ ì •ë ¬(íŒŒì‹± ì‹¤íŒ¨ í•­ëª©ì€ ë’¤ë¡œ)
    def _sort_key(it: Dict[str, Any]):
        ds = it.get("date")
        try:
            d = date.fromisoformat(ds) if isinstance(ds, str) else None
        except Exception:
            d = None
        return (1, date.max) if d is None else (0, d)

    items = sorted(items, key=_sort_key)

    # ê°„ë‹¨ í…ìŠ¤íŠ¸(ë„êµ¬ í˜¸ì¶œìê°€ ê·¸ëŒ€ë¡œ ë³´ì—¬ì¤„ ìˆ˜ ìˆë„ë¡)
    lines: List[str] = []
    for it in items:
        if it.get("d_day") and it.get("weekday_ko"):
            lines.append(f"{it['d_day']} Â· {it['name']} ({it['date']} {it['weekday_ko']})")
        elif it.get("d_day"):
            lines.append(f"{it['d_day']} Â· {it['name']} ({it['date']})")
        else:
            lines.append(f"â€” Â· {it.get('name')} ({it.get('date')})")

    return json.dumps(
        {
            "status": "success",
            "source": "derived_hardcoded_2026",
            "today": today_date.isoformat(),
            "query": q,
            "items": items,
            "text": "\n".join(lines)[:1500],
        },
        ensure_ascii=False,
    )

# =========================
# Campus Contact Directory (Offline-first)
# =========================

_CAMPUS_CONTACT_DIRECTORY: Dict[str, Dict[str, str]] = {
    "Emergency": {
        "Integrated_Security_Office": "051-410-4112",
        "Campus_Police_Station": "051-410-4112",
        "Night_Guard_Office": "051-410-4111",
    },
    "Academic_Affairs": {
        "Academic_Management": "051-410-4011",
        "Admissions_Team": "051-410-4771",
        "International_Affairs": "051-410-4761",
        "Registrar_Office": "051-410-4012",
    },
    "Student_Services": {
        "Student_Support_Team": "051-410-4022",
        "Scholarship_Office": "051-410-4024",
        "Health_Center": "051-410-4066",
        "Counseling_Center": "051-410-4065",
    },
    "Campus_Facilities": {
        "Library_Information": "051-410-4071",
        "Dormitory_Administration": "051-410-4054",
        "Cafeteria_Management": "051-410-4114",
        "IT_Support_Center": "051-410-4082",
    },
    "Main_Office": {
        "KMOU_Representative": "051-410-4114",
    },
}

def _pretty_key(s: str) -> str:
    return (s or "").replace("_", " ").strip()

_CONTACT_CATEGORY_KO = {
    "Emergency": "ê¸´ê¸‰",
    "Academic_Affairs": "í•™ì‚¬",
    "Student_Services": "í•™ìƒì§€ì›",
    "Campus_Facilities": "ì‹œì„¤",
    "Main_Office": "ëŒ€í‘œ",
}

_CONTACT_OFFICE_KO = {
    "Integrated_Security_Office": "í†µí•©ë³´ì•ˆì‹¤",
    "Campus_Police_Station": "êµë‚´ ê²½ì°°/ì¹˜ì•ˆ",
    "Night_Guard_Office": "ì•¼ê°„ ê²½ë¹„ì‹¤",
    "Academic_Management": "í•™ì‚¬ê´€ë¦¬",
    "Admissions_Team": "ì…í•™íŒ€",
    "International_Affairs": "êµ­ì œêµë¥˜",
    "Registrar_Office": "í•™ì /ì œì¦ëª…",
    "Student_Support_Team": "í•™ìƒì§€ì›íŒ€",
    "Scholarship_Office": "ì¥í•™",
    "Health_Center": "ë³´ê±´ì‹¤",
    "Counseling_Center": "ìƒë‹´ì„¼í„°",
    "Library_Information": "ë„ì„œê´€",
    "Dormitory_Administration": "ê¸°ìˆ™ì‚¬ í–‰ì •",
    "Cafeteria_Management": "ì‹ë‹¹/êµ¬ë‚´ì‹ë‹¹",
    "IT_Support_Center": "IT ì§€ì›ì„¼í„°",
    "KMOU_Representative": "í•™êµ ëŒ€í‘œë²ˆí˜¸",
}

def get_campus_contacts(category: Optional[str] = None, office: Optional[str] = None, lang: str = "ko"):
    """
    ì˜¤í”„ë¼ì¸ ìº í¼ìŠ¤ ì—°ë½ì²˜ ë””ë ‰í† ë¦¬(ì§„ì‹¤ ì†ŒìŠ¤: _CAMPUS_CONTACT_DIRECTORY)
    - category=None: ì¹´í…Œê³ ë¦¬ ëª©ë¡ ë°˜í™˜
    - category ì§€ì •: í•´ë‹¹ ì¹´í…Œê³ ë¦¬ì˜ ì—°ë½ì²˜ ëª©ë¡ ë°˜í™˜
    - office ì§€ì •: officeë¥¼ ì „ì²´ ì¹´í…Œê³ ë¦¬ì—ì„œ ê²€ìƒ‰í•˜ì—¬ ë‹¨ì¼ í•­ëª© ë°˜í™˜
    """
    lang = (lang or "ko").strip().lower()
    if lang not in {"ko", "en"}:
        lang = "ko"

    if office:
        key = (office or "").strip()
        for cat, mp in _CAMPUS_CONTACT_DIRECTORY.items():
            if key in mp:
                return json.dumps(
                    {
                        "status": "success",
                        "mode": "office",
                        "category": cat,
                        "office": key,
                        "office_label": (_pretty_key(key) if lang == "en" else (_CONTACT_OFFICE_KO.get(key) or _pretty_key(key))),
                        "phone": mp[key],
                    },
                    ensure_ascii=False,
                )
        return json.dumps(
            {"status": "empty", "msg": ("Contact not found." if lang == "en" else "í•´ë‹¹ ì—°ë½ì²˜ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")},
            ensure_ascii=False,
        )

    if category:
        cat = (category or "").strip()
        mp = _CAMPUS_CONTACT_DIRECTORY.get(cat)
        if not mp:
            return json.dumps(
                {"status": "empty", "msg": ("Category not found." if lang == "en" else "í•´ë‹¹ ë¶„ë¥˜ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")},
                ensure_ascii=False,
            )
        contacts = [
            {
                "office": k,
                "office_label": (_pretty_key(k) if lang == "en" else (_CONTACT_OFFICE_KO.get(k) or _pretty_key(k))),
                "phone": v,
            }
            for k, v in mp.items()
        ]
        return json.dumps(
            {
                "status": "success",
                "mode": "category",
                "category": cat,
                "category_label": (_pretty_key(cat) if lang == "en" else (_CONTACT_CATEGORY_KO.get(cat) or _pretty_key(cat))),
                "contacts": contacts,
            },
            ensure_ascii=False,
        )

    categories = [
        {
            "category": c,
            "category_label": (_pretty_key(c) if lang == "en" else (_CONTACT_CATEGORY_KO.get(c) or _pretty_key(c))),
            "count": len(mp),
        }
        for c, mp in _CAMPUS_CONTACT_DIRECTORY.items()
    ]
    return json.dumps({"status": "success", "mode": "categories", "categories": categories}, ensure_ascii=False)

async def get_astronomy_data(target_date: str):
    """
    KASI Rise/Set Time Information Service
    - Endpoint: http://apis.data.go.kr/B090041/openapi/service/RiseSetInfoService/getAreaRiseSetInfo
    - Params: serviceKey, locdate(YYYYMMDD), location('ë¶€ì‚°')
    - Strict fallback: ì‹¤íŒ¨ ì‹œ Update Pending(ì„ì˜ ì‹œê°„ ìƒì„± ê¸ˆì§€)
    """
    if not DATA_GO_KR_SERVICE_KEY:
        return json.dumps(
            {"status": "pending", "msg": "Update Pending", "location": "ë¶€ì‚°", "date": None, "sunrise": "Update Pending", "sunset": "Update Pending"},
            ensure_ascii=False,
        )

    digits = re.sub(r"\D+", "", str(target_date or ""))
    if len(digits) != 8:
        digits = _reference_datetime().strftime("%Y%m%d")

    cache_key = f"{digits}:ë¶€ì‚°"
    cached = _ASTRO_CACHE.get(cache_key)
    if cached and (time.time() - cached[0] <= _ASTRO_CACHE_TTL_SECONDS):
        return cached[1]

    url = "http://apis.data.go.kr/B090041/openapi/service/RiseSetInfoService/getAreaRiseSetInfo"
    timeout_s = float(os.environ.get("ARA_ASTRONOMY_TIMEOUT_SECONDS", "2.0"))

    try:
        async with httpx.AsyncClient(headers=HEADERS) as client:
            res = await client.get(
                url,
                params={"serviceKey": DATA_GO_KR_SERVICE_KEY, "locdate": digits, "location": "ë¶€ì‚°"},
                timeout=timeout_s,
            )
        text = res.text or ""

        sunrise_raw = None
        sunset_raw = None

        # 1) JSON ì‘ë‹µ(ì§€ì›ë˜ëŠ” ê²½ìš°)
        if text.lstrip().startswith("{"):
            try:
                data = res.json()

                def _jget(d: Any, *keys: str) -> Any:
                    cur = d
                    for k in keys:
                        if not isinstance(cur, dict):
                            return None
                        cur = cur.get(k)
                    return cur

                code = _jget(data, "response", "header", "resultCode")
                if code and str(code) not in {"00", "0"}:
                    raise RuntimeError("resultCode not OK")
                item = _jget(data, "response", "body", "items", "item") or _jget(data, "response", "body", "item")
                if isinstance(item, list) and item:
                    item = item[0]
                if isinstance(item, dict):
                    sunrise_raw = item.get("sunrise")
                    sunset_raw = item.get("sunset")
            except Exception:
                sunrise_raw = None
                sunset_raw = None

        # 2) XML ì‘ë‹µ(ê¸°ë³¸)
        if sunrise_raw is None or sunset_raw is None:
            if "<resultCode>00</resultCode>" not in text:
                raise RuntimeError("resultCode not OK")

            import xml.etree.ElementTree as ET

            root = ET.fromstring(text)
            # ë¬¸ì„œ êµ¬ì¡° ì°¨ì´ì— ëŒ€ë¹„í•´ íƒœê·¸ë¥¼ ì „ì—­ íƒìƒ‰
            sr = root.find(".//sunrise")
            ss = root.find(".//sunset")
            if sr is not None and sr.text:
                sunrise_raw = sr.text.strip()
            if ss is not None and ss.text:
                sunset_raw = ss.text.strip()

        sunrise = _format_hhmm(sunrise_raw or "")
        sunset = _format_hhmm(sunset_raw or "")
        if not sunrise or not sunset:
            raise RuntimeError("missing sunrise/sunset")

        payload = json.dumps(
            {
                "status": "success",
                "location": "ë¶€ì‚°",
                "date": digits,
                "sunrise": sunrise,
                "sunset": sunset,
                "raw": {"sunrise": sunrise_raw, "sunset": sunset_raw},
            },
            ensure_ascii=False,
        )
        _ASTRO_CACHE[cache_key] = (time.time(), payload)
        return payload
    except Exception:
        payload = json.dumps(
            {"status": "pending", "msg": "Update Pending", "location": "ë¶€ì‚°", "date": digits, "sunrise": "Update Pending", "sunset": "Update Pending"},
            ensure_ascii=False,
        )
        _ASTRO_CACHE[cache_key] = (time.time(), payload)
        return payload
# ìœ„ì¹˜ í•„í„°ë§(ë¬´í™˜ê°): KMOU ì¢Œí‘œ(Wikidata ê¸°ë°˜)
# - ìœ„/ê²½ë„ëŠ” ê²€ìƒ‰/í•„í„°ë§ì—ë§Œ ì‚¬ìš©(ì‘ë‹µì— ì„ì˜ ìƒì„± ì¢Œí‘œëŠ” ì ˆëŒ€ í¬í•¨í•˜ì§€ ì•ŠìŒ)
_KMOU_LAT = 35.074441
_KMOU_LON = 129.086944

def _haversine_m(lat1: float, lon1: float, lat2: float, lon2: float) -> float:
    import math

    r = 6371000.0
    p1 = math.radians(lat1)
    p2 = math.radians(lat2)
    dlat = math.radians(lat2 - lat1)
    dlon = math.radians(lon2 - lon1)
    a = math.sin(dlat / 2) ** 2 + math.cos(p1) * math.cos(p2) * math.sin(dlon / 2) ** 2
    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))
    return r * c

def _is_near_kmou(lat: Optional[float], lon: Optional[float], radius_m: float = 5000.0) -> Tuple[bool, Optional[int]]:
    if lat is None or lon is None:
        return (False, None)
    try:
        dist = _haversine_m(float(lat), float(lon), _KMOU_LAT, _KMOU_LON)
        return (dist <= radius_m, int(dist))
    except Exception:
        return (False, None)

def _reference_datetime() -> datetime:
    """
    ê¸°ì¤€ ì‹œê°
    - ìš´ì˜(Render): ì‹œìŠ¤í…œ ì‹œê°(datetime.now) ì‚¬ìš©
    - í…ŒìŠ¤íŠ¸: ARA_REF_DATE/ARA_REF_TIMEë¡œ ì˜¤ë²„ë¼ì´ë“œ ê°€ëŠ¥
    """
    if not ARA_REF_DATE and not ARA_REF_TIME:
        return datetime.now(_KST)
    d = re.sub(r"\D+", "", ARA_REF_DATE)
    t = re.sub(r"\D+", "", ARA_REF_TIME)
    if len(d) != 8:
        return datetime.now(_KST)
    if len(t) not in (3, 4):
        return datetime.now(_KST)
    if len(t) == 3:
        t = "0" + t
    try:
        return datetime(int(d[0:4]), int(d[4:6]), int(d[6:8]), int(t[0:2]), int(t[2:4]), tzinfo=_KST)
    except Exception:
        return datetime.now(_KST)
    # NOTE: í•™ì‹ ë©”ë‰´ í¬ë¡¤ë§/ìºì‹œ ë¡œì§ì€ ìš”êµ¬ì‚¬í•­ì— ë”°ë¼ íê¸°ë˜ì—ˆìŠµë‹ˆë‹¤.

def _extract_ymd(date_text: str) -> Optional[datetime]:
    """ë¬¸ìì—´ì—ì„œ YYYYMMDD(ë˜ëŠ” YYYY-MM-DD/YYë…„MMì›”DDì¼ ë“±) ì¶”ì¶œ. ë¶ˆí™•ì‹¤í•˜ë©´ None."""
    if not date_text:
        return None
    s = str(date_text)
    m = re.search(r"(?P<y>20\d{2})\s*[.\-/ë…„]\s*(?P<m>\d{1,2})\s*[.\-/ì›”]\s*(?P<d>\d{1,2})", s)
    if not m:
        m = re.search(r"(?P<y>20\d{2})\s*(?P<m>\d{2})\s*(?P<d>\d{2})", re.sub(r"\D+", "", s))
    if not m:
        return None
    try:
        return datetime(int(m.group("y")), int(m.group("m")), int(m.group("d")))
    except Exception:
        return None

def _parse_hours_range(s: str) -> Optional[Tuple[int, int]]:
    """
    '09:00~18:00' -> (540, 1080) ë¶„ ë‹¨ìœ„.
    ë¶ˆí™•ì‹¤í•˜ë©´ None.
    """
    if not s:
        return None
    m = re.search(r"(?P<sh>\d{1,2})\s*:\s*(?P<sm>\d{2})\s*~\s*(?P<eh>\d{1,2})\s*:\s*(?P<em>\d{2})", str(s))
    if not m:
        return None
    try:
        sh, sm, eh, em = int(m.group("sh")), int(m.group("sm")), int(m.group("eh")), int(m.group("em"))
        return (sh * 60 + sm, eh * 60 + em)
    except Exception:
        return None

def _extract_digits(s: str) -> str:
    """ì˜¤íƒ€/ì ‘ë¯¸ì‚¬(190qjs, 190ë²ˆ ë“±)ì—ì„œ ìˆ«ìë§Œ ì¶”ì¶œ"""
    if not s:
        return ""
    return "".join(re.findall(r"\d+", str(s)))

def _safe_get(d: Any, *keys: str, default: Any = None) -> Any:
    cur = d
    for k in keys:
        if not isinstance(cur, dict):
            return default
        cur = cur.get(k)
    return default if cur is None else cur

def _strip_html(s: str) -> str:
    if not s:
        return ""
    return re.sub(r"<[^>]+>", "", str(s)).strip()

_CACHE: Dict[str, Tuple[float, Any]] = {}

def _make_cache_key(prefix: str, url: str, params: Dict[str, Any]) -> str:
    frozen = tuple(sorted((k, str(v)) for k, v in (params or {}).items()))
    return f"{prefix}:{url}:{frozen}"

def _cache_get(key: str) -> Optional[Any]:
    now = time.time()
    item = _CACHE.get(key)
    if not item:
        return None
    ts, value = item
    if now - ts > CACHE_TTL_SECONDS:
        _CACHE.pop(key, None)
        return None
    return value

def _cache_set(key: str, value: Any) -> None:
    _CACHE[key] = (time.time(), value)

async def _http_get_json(
    url: str,
    params: Dict[str, Any],
    timeout: float = 10.0,
    client: Optional[httpx.AsyncClient] = None,
) -> Dict[str, Any]:
    cache_key = _make_cache_key("GETJSON", url, params)
    cached = _cache_get(cache_key)
    if cached is not None:
        return {"status": "success", "data": cached, "cached": True}

    try:
        if client is None:
            async with httpx.AsyncClient(verify=HTTPX_VERIFY, headers=HEADERS) as _client:
                res = await _client.get(url, params=params, timeout=timeout)
        else:
            res = await client.get(url, params=params, timeout=timeout)
        res.raise_for_status()
        data = res.json()
        _cache_set(cache_key, data)
        return {"status": "success", "data": data, "cached": False}
    except Exception as e:
        return {"status": "error", "msg": str(e)}

# =========================
# 1) ë‚ ì”¨ ì •ë³´ ì‹¤ì‹œê°„ ì—°ë™ (ê¸°ìƒì²­ API) â€” ìš”ì²­ êµì •ë³¸ ë°˜ì˜
# =========================

async def get_kmou_weather(lang: str = "ko"):
    """í•œêµ­í•´ì–‘ëŒ€(ì˜ë„êµ¬ ë™ì‚¼ë™) ì‹¤ì‹œê°„ ê¸°ìƒ ì‹¤í™© ì¡°íšŒ (lang: ko/en)"""
    lang = (lang or "ko").strip().lower()
    if lang not in {"ko", "en"}:
        lang = "ko"
    if not DATA_GO_KR_SERVICE_KEY:
        return json.dumps(
            {
                "status": "error",
                "msg": ("Weather API key (DATA_GO_KR_SERVICE_KEY) is missing." if lang == "en" else "ê¸°ìƒì²­ API í‚¤(DATA_GO_KR_SERVICE_KEY)ê°€ ì—†ìŠµë‹ˆë‹¤."),
            },
            ensure_ascii=False,
        )

    url = "http://apis.data.go.kr/1360000/VilageFcstInfoService_2.0/getUltraSrtNcst"
    # ìš”êµ¬ì‚¬í•­: ì‹œìŠ¤í…œ ì‹œê°ê³¼ ë™ê¸°í™”ëœ base_time ì‚¬ìš©(ìš´ì˜ ê¸°ë³¸)
    # - getUltraSrtNcstëŠ” ë³´í†µ HH00 ë‹¨ìœ„ ê°±ì‹ ì´ë¯€ë¡œ HH00 ê¸°ì¤€ìœ¼ë¡œ ì¡°íšŒí•˜ê³ , ì‹¤íŒ¨ ì‹œ ì „ ì‹œê°ìœ¼ë¡œ í´ë°±í•©ë‹ˆë‹¤.
    now = _reference_datetime()
    base_date = now.strftime("%Y%m%d")
    base_time_primary = now.strftime("%H00")

    # ì•ˆì •ì„±: ê¸°ë³¸ êµì • ë¡œì§(00/30) + ì‹¤íŒ¨ ì‹œ ì „ ì‹œê°(HH00) fallback
    candidates: List[Tuple[str, str]] = [(base_date, base_time_primary)]
    # ì „ 1ì‹œê°„ HH00 fallback(ê°€ì¥ í”í•œ ì§€ì—°/ëˆ„ë½ ì¼€ì´ìŠ¤)
    prev = now - timedelta(hours=1)
    candidates.append((prev.strftime("%Y%m%d"), prev.strftime("%H00")))

    last_error: Optional[str] = None
    for cand_date, cand_time in candidates:
        params = {
            "serviceKey": DATA_GO_KR_SERVICE_KEY,
            "pageNo": "1",
            "numOfRows": "10",
            "dataType": "JSON",
            "base_date": cand_date,
            "base_time": cand_time,
            # ìš”êµ¬ì‚¬í•­: ì˜ë„êµ¬ ê²©ì ì¢Œí‘œ
            "nx": "96",
            "ny": "74",
        }

        try:
            async with httpx.AsyncClient(verify=HTTPX_VERIFY, headers=HEADERS) as client:
                res = await client.get(url, params=params, timeout=10.0)
                data = res.json()

            # ì‘ë‹µ êµ¬ì¡° fail-safe
            code = _safe_get(data, "response", "header", "resultCode", default=None)
            if code and code not in {"00", "0"}:
                last_error = _safe_get(data, "response", "header", "resultMsg", default="API ì˜¤ë¥˜")
                continue

            items = _safe_get(data, "response", "body", "items", "item", default=[])
            if not isinstance(items, list) or not items:
                last_error = "ë‚ ì”¨ raw dataê°€ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤."
                continue

            weather_info: Dict[str, Any] = {}
            for item in items:
                if item.get("category") == "T1H":
                    weather_info["temp"] = item.get("obsrValue")
                if item.get("category") == "PTY":
                    weather_info["state"] = item.get("obsrValue")
                # í’ì†(WSD, m/s): getUltraSrtNcst í‘œì¤€ ì œê³µ í•­ëª©(ì—†ì„ ìˆ˜ ìˆì–´ ì•ˆì „í•˜ê²Œ ì²˜ë¦¬)
                if item.get("category") == "WSD":
                    weather_info["wind_speed"] = item.get("obsrValue")

            location = "Busan, Yeongdo-gu" if lang == "en" else "ë¶€ì‚°ê´‘ì—­ì‹œ ì˜ë„êµ¬"
            return json.dumps(
                {
                    "status": "success",
                    "weather": {
                        "temp": f"{weather_info.get('temp', 'N/A')}Â°C",
                        "location": location,
                        "date": cand_date,
                        "time": cand_time,
                        # raw data ì¼ë¶€ë¥¼ í•¨ê»˜ í¬í•¨(ìˆ«ì ê·¼ê±° ì œê³µ)
                        "raw": weather_info,
                    },
                },
                ensure_ascii=False,
            )
        except Exception as e:
            last_error = str(e)
            continue

    return json.dumps(
        {
            "status": "error",
            "msg": (f"Weather fetch failed: {last_error or 'unknown'}" if lang == "en" else f"ë‚ ì”¨ ì¡°íšŒ ì‹¤íŒ¨: {last_error or 'unknown'}"),
        },
        ensure_ascii=False,
    )

def _wind_intensity_desc_ko(wind_speed_ms: float) -> str:
    """
    í’ì†(m/s) â†’ í•™ìƒ ì¹œí™”ì  ê°•ë„ ì„¤ëª…(ìš”êµ¬ì‚¬í•­)
    - 0.0 ~ 1.0: ê³ ìš”í•¨
    - 1.0 ~ 4.0: ì„ ì„ í•œ ë°”ëŒ
    - 4.0 ~ 9.0: ë°”ëŒ ë‹¤ì†Œ ê°•í•¨
    - 9.0 ì´ìƒ: âš ï¸ ê°•í’ ì£¼ì˜
    """
    v = float(wind_speed_ms or 0.0)
    if v <= 1.0:
        return "ê³ ìš”í•¨"
    if v < 4.0:
        return "ì„ ì„ í•œ ë°”ëŒ"
    if v < 9.0:
        return "ë°”ëŒ ë‹¤ì†Œ ê°•í•¨"
    return "âš ï¸ ê°•í’ ì£¼ì˜"

def _fmt_num(x: float) -> str:
    """0.0/1.0 ê°™ì€ ê°’ì€ '0'/'1'ë¡œ, ê·¸ ì™¸ëŠ” ì†Œìˆ˜ 1ìë¦¬ë¡œ í‘œì‹œ."""
    try:
        v = float(x)
    except Exception:
        v = 0.0
    s = f"{v:.1f}"
    return s.rstrip("0").rstrip(".")

def _wind_chill_c(temp_c: float, wind_speed_ms: float) -> float:
    t = float(temp_c or 0.0)
    v_kmh = float(wind_speed_ms or 0.0) * 3.6
    if t <= 10.0 and v_kmh > 4.8:
        return 13.12 + 0.6215 * t - 11.37 * (v_kmh ** 0.16) + 0.3965 * t * (v_kmh ** 0.16)
    return t

async def get_weather_info(lang: str = "ko") -> str:
    """
    ì˜ë„ ë‚ ì”¨(í’ì† í¬í•¨) â€” UIëŠ” main.pyì—ì„œ ì¹´ë“œë¡œ êµ¬ì„±
    - ë°˜í™˜: json ë¬¸ìì—´
    - ì•ˆì •ì„±: OpenWeatherMap(ìˆìœ¼ë©´) â†’ KMA(get_kmou_weather) í´ë°±
    """
    lang = (lang or "ko").strip().lower()
    if lang not in {"ko", "en"}:
        lang = "ko"

    try:
        data: Dict[str, Any] = {}

        # 1) OpenWeatherMap(ìˆë‹¤ë©´) ì‚¬ìš© â€” free APIì—ì„œ ë³´ì¥ë˜ëŠ” í•„ë“œë§Œ ì‚¬ìš©
        owm_key = (os.environ.get("OPENWEATHER_API_KEY") or os.environ.get("OPENWEATHERMAP_API_KEY") or "").strip()
        if owm_key:
            try:
                url = "https://api.openweathermap.org/data/2.5/weather"
                params = {
                    "lat": str(_KMOU_LAT),
                    "lon": str(_KMOU_LON),
                    "appid": owm_key,
                    "units": "metric",
                }
                async with httpx.AsyncClient(verify=HTTPX_VERIFY, headers=HEADERS) as client:
                    res = await client.get(url, params=params, timeout=5.0)
                res.raise_for_status()
                data = res.json() or {}
            except Exception:
                data = {}

        # 2) KMA í´ë°±
        if not data:
            raw = await get_kmou_weather(lang=lang)
            payload = json.loads(raw) if isinstance(raw, str) else (raw or {})
            if not isinstance(payload, dict) or payload.get("status") != "success":
                return json.dumps(
                    {"status": "error", "msg": "ë‚ ì”¨ ì •ë³´ë¥¼ í™•ì¸ ì¤‘ì…ë‹ˆë‹¤."},
                    ensure_ascii=False,
                )
            w = payload.get("weather") or {}
            raw_weather = w.get("raw") if isinstance(w, dict) else {}
            if not isinstance(raw_weather, dict):
                raw_weather = {}
            # ê¸°ìƒì²­ ì‹¤í™©: ì²´ê°ì˜¨ë„ ì—†ìŒ â†’ wind chill(ê°€ëŠ¥ ì‹œ) ê³„ì‚°
            data = {
                "main": {
                    "temp": raw_weather.get("temp"),
                    "feels_like": raw_weather.get("feels_like"),
                },
                "wind": {"speed": raw_weather.get("wind_speed")},
            }

        main = data.get("main") if isinstance(data, dict) else {}
        wind = data.get("wind") if isinstance(data, dict) else {}
        if not isinstance(main, dict):
            main = {}
        if not isinstance(wind, dict):
            wind = {}

        temp = float(main.get("temp") or 0.0)
        feels_raw = main.get("feels_like")
        feels = float(feels_raw) if feels_raw is not None else temp
        wind_speed = float(wind.get("speed") or 0.0)
        wind_text = _wind_intensity_desc_ko(wind_speed)

        if feels_raw is None:
            feels = float(_wind_chill_c(temp, wind_speed))

        return json.dumps(
            {
                "status": "success",
                "temp": temp,
                "feels_like": feels,
                "wind_speed": wind_speed,
                "wind_text": wind_text,
            },
            ensure_ascii=False,
        )
    except Exception:
        return json.dumps({"status": "error", "msg": "ë‚ ì”¨ ì •ë³´ë¥¼ í™•ì¸ ì¤‘ì…ë‹ˆë‹¤."}, ensure_ascii=False)

# =========================
# 2) ë²„ìŠ¤ í•„í„°ë§ ë¡œì§ ìµœì í™” (ODsay) â€” ìš”ì²­ êµì •ë³¸ ë°˜ì˜
# =========================

async def get_bus_arrival(bus_number: str = None, direction: str = None, lang: str = "ko") -> str:
    """
    190ë²ˆ ë²„ìŠ¤ ë„ì°©ì •ë³´(OUT ê³ ì • / 03053)
    - UIëŠ” main.pyì—ì„œ BasicCard/ListCardë¡œ êµ¬ì„±(ìš”êµ¬ì‚¬í•­: BasicCard thumbnail ì œê±°)
    - ë°˜í™˜: json ë¬¸ìì—´
    """
    lang = (lang or "ko").strip().lower()
    if lang not in {"ko", "en"}:
        lang = "ko"

    # 190ë§Œ ì§€ì›
    req_num = _extract_digits(bus_number) if bus_number else "190"
    if req_num and req_num != "190":
        return json.dumps({"status": "error", "msg": "í˜„ì¬ëŠ” 190ë²ˆ ë²„ìŠ¤ë§Œ ì§€ì›í•©ë‹ˆë‹¤."}, ensure_ascii=False)

    # OUT ê³ ì •: í•´ì–‘ëŒ€ì…êµ¬(ë‚¨í¬/ì‹œë‚´í–‰)
    station_id = "03053"

    if not DATA_GO_KR_SERVICE_KEY:
        return json.dumps({"status": "error", "msg": "ê³µê³µë°ì´í„° API í‚¤(DATA_GO_KR_SERVICE_KEY)ê°€ ì—†ìŠµë‹ˆë‹¤."}, ensure_ascii=False)

    target_bus_num = "190"

    # ë¶€ì‚°BIMS: ì •ë¥˜ì†Œ ë„ì°©ì •ë³´(ARSë²ˆí˜¸) ì¡°íšŒ
    # - ì¼ë¶€ APIëŠ” arsnoì—ì„œ ì„ í–‰ 0ì„ í—ˆìš©í•˜ì§€ ì•ŠëŠ” ê²½ìš°ê°€ ìˆì–´ 2íšŒ ì‹œë„í•©ë‹ˆë‹¤.
    ars_candidates = [station_id]
    stripped = station_id.lstrip("0")
    if stripped and stripped != station_id:
        ars_candidates.append(stripped)

    busan_bims_url = "http://apis.data.go.kr/6260000/BusanBIMS/bitArrByArsno"
    busan_timeout = float(os.environ.get("ARA_BUS_TIMEOUT_SECONDS", "2.5"))

    def _parse_items_xml(xml_text: str) -> List[Dict[str, Any]]:
        """
        ë¶€ì‚°BIMS bitArrByArsno XML íŒŒì‹±(ë‹¤ìŒ/ë‹¤ë‹¤ìŒ ë²„ìŠ¤)
        - min1/station1: ë‹¤ìŒ ë²„ìŠ¤
        - min2/station2: ë‹¤ë‹¤ìŒ ë²„ìŠ¤
        ë°˜í™˜ ì˜ˆ(ìš”êµ¬ì‚¬í•­):
        {
          "line": "190",
          "bus1": {"min": "11", "stop": "8"},
          "bus2": {"min": "30", "stop": "21"}
        }
        """
        import xml.etree.ElementTree as ET

        try:
            root = ET.fromstring(xml_text)
        except Exception:
            return []
        items_el = root.find("./body/items")
        if items_el is None:
            return []
        out: List[Dict[str, Any]] = []
        for it in items_el.findall("./item"):
            d: Dict[str, str] = {}
            for child in list(it):
                if child.tag and child.text is not None:
                    d[child.tag] = child.text
            if not d:
                continue

            line = _extract_digits(d.get("lineno") or "")
            if not line:
                continue

            min1 = (d.get("min1") or "").strip()
            st1 = (d.get("station1") or "").strip()
            min2 = (d.get("min2") or "").strip()
            st2 = (d.get("station2") or "").strip()

            payload: Dict[str, Any] = {
                "line": line,
                "bus1": {"min": min1, "stop": st1} if min1 else None,
                "bus2": {"min": min2, "stop": st2} if min2 else None,
            }
            out.append(payload)
        return out

    items: List[Dict[str, Any]] = []
    last_err: Optional[str] = None
    last_xml_text: str = ""
    last_status_code: Optional[int] = None
    for arsno in ars_candidates:
        try:
            async with httpx.AsyncClient(verify=HTTPX_VERIFY, headers=HEADERS) as client:
                res = await client.get(
                    busan_bims_url,
                    params={"serviceKey": DATA_GO_KR_SERVICE_KEY, "arsno": arsno, "numOfRows": "50", "pageNo": "1"},
                    timeout=busan_timeout,
                )
            last_status_code = res.status_code
            xml_text = res.text or ""
            last_xml_text = xml_text
            # ì •ìƒì½”ë“œ ì²´í¬(00ë§Œ í†µê³¼)
            if "<resultCode>00</resultCode>" not in xml_text:
                last_err = "ê³µê³µë°ì´í„° ì‘ë‹µì´ ì •ìƒì½”ë“œê°€ ì•„ë‹™ë‹ˆë‹¤."
                continue
            parsed = _parse_items_xml(xml_text)
            # 200 + resultCode 00 ì¸ë° itemsê°€ ë¹„ì–´ìˆì„ ìˆ˜ ìˆìŒ(ìš´í–‰ ì—†ìŒ ì¼€ì´ìŠ¤)
            items = parsed or []
            break
        except Exception as e:
            last_err = str(e)
            continue

    # 200ì¸ë° ë°ì´í„°ê°€ ë¹„ë©´: ìš´í–‰ ì¤‘ ë²„ìŠ¤ ì—†ìŒ(ìš”êµ¬ì‚¬í•­ ë¬¸êµ¬)
    if (last_status_code == 200) and ("<resultCode>00</resultCode>" in (last_xml_text or "")) and (not items):
        return json.dumps({"status": "empty", "msg": "í˜„ì¬ ìš´í–‰ ì¤‘ì¸ 190ë²ˆ ë²„ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤ (ì°¨ê³ ì§€ ëŒ€ê¸° ì¤‘)"}, ensure_ascii=False)

    if not items:
        # ê³µê³µë°ì´í„° ì¥ì• /ë¹„ì •ìƒ ì‘ë‹µ(ë³´ìˆ˜ì  ë¬¸êµ¬)
        return json.dumps(
            {"status": "error", "msg": "í˜„ì¬ 2026-01-20 ì‹¤ì‹œê°„ ë²„ìŠ¤ ì •ë³´ê°€ ì„œë²„ì—ì„œ ì‘ë‹µí•˜ì§€ ì•ŠìŠµë‹ˆë‹¤", "detail": last_err or "empty"},
            ensure_ascii=False,
        )

    # 190ë²ˆ: bus1(ë‹¤ìŒ) + bus2(ë‹¤ë‹¤ìŒ) ì¶”ì¶œ
    found_190: Optional[Dict[str, Any]] = None
    for it in items:
        if str(it.get("line") or "").strip() != "190":
            continue
        found_190 = it
        break

    if not found_190:
        return json.dumps({"status": "empty", "msg": "í˜„ì¬ ìš´í–‰ ì¤‘ì¸ 190ë²ˆ ë²„ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤ (ì°¨ê³ ì§€ ëŒ€ê¸° ì¤‘)"}, ensure_ascii=False)

    b1 = found_190.get("bus1") if isinstance(found_190, dict) else None
    b2 = found_190.get("bus2") if isinstance(found_190, dict) else None

    # ë‹¤ìŒ ë²„ìŠ¤(min1) ì—†ìœ¼ë©´: ìš´í–‰ ì—†ìŒìœ¼ë¡œ ì²˜ë¦¬
    if (not isinstance(b1, dict)) or (not str(b1.get("min") or "").strip()):
        return json.dumps({"status": "empty", "msg": "í˜„ì¬ ìš´í–‰ ì¤‘ì¸ 190ë²ˆ ë²„ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤ (ì°¨ê³ ì§€ ëŒ€ê¸° ì¤‘)"}, ensure_ascii=False)

    min1 = str(b1.get("min") or "").strip()
    st1 = str(b1.get("stop") or "").strip() or "?"

    min2 = ""
    st2 = ""
    if isinstance(b2, dict):
        min2 = str(b2.get("min") or "").strip()
        st2 = str(b2.get("stop") or "").strip()

    return json.dumps(
        {
            "status": "success",
            "line": "190",
            "direction": "OUT",
            "station_id": station_id,
            "station_label": "í•´ì–‘ëŒ€ì…êµ¬(ë‚¨í¬/ì‹œë‚´í–‰)",
            "bus1": {"min": min1, "stop": st1},
            "bus2": {"min": (min2 or None), "stop": (st2 or None)},
        },
        ensure_ascii=False,
    )

_BUS_190_KMOU_MAIN_TIMETABLE: Dict[str, List[str]] = {
    "Mon": ["04:55", "05:10", "05:25", "05:40", "05:55", "06:11", "06:25", "06:40", "06:55", "07:10", "07:27", "07:45", "08:04", "08:22", "08:41", "09:01", "09:20", "09:40", "09:59", "10:20", "10:40", "11:00", "11:20", "11:43", "12:02", "12:21", "12:40", "12:59", "13:18", "13:37", "13:56", "14:15", "14:34", "14:54", "15:12", "15:29", "15:47", "16:07", "16:26", "16:45", "17:04", "17:23", "17:42", "18:01", "18:19", "18:39", "18:57", "19:18", "19:37", "19:56", "20:14", "20:34", "20:53", "21:12", "21:30", "21:49"],
    "Tue": ["04:55", "05:10", "05:25", "05:40", "05:55", "06:10", "06:25", "06:40", "06:55", "07:10", "07:27", "07:45", "08:04", "08:23", "08:43", "09:00", "09:19", "09:39", "10:00", "10:20", "10:39", "11:00", "11:20", "11:43", "12:02", "12:21", "12:40", "12:59", "13:18", "13:37", "13:56", "14:15", "14:34", "14:53", "15:13", "15:28", "15:48", "16:07", "16:26", "16:45", "17:04", "17:23", "17:42", "18:01", "18:20", "18:39", "18:58", "19:17", "19:37", "19:56", "20:15", "20:34", "20:53", "21:11", "21:30", "21:49"],
    "Wed": ["04:55", "05:10", "05:25", "05:40", "05:55", "06:10", "06:25", "06:40", "06:55", "07:10", "07:27", "07:45", "08:04", "08:23", "08:42", "09:01", "09:20", "09:40", "10:00", "10:20", "10:40", "10:59", "11:19", "11:43", "12:02", "12:21", "12:40", "12:59", "13:18", "13:37", "13:56", "14:15", "14:34", "14:53", "15:12", "15:28", "15:48", "16:07", "16:26", "16:45", "17:04", "17:23", "17:42", "18:01", "18:20", "18:39", "18:58", "19:18", "19:36", "19:56", "20:15", "20:34", "20:52", "21:12", "21:31", "21:49"],
    "Thu": ["04:55", "05:10", "05:25", "05:40", "05:55", "06:10", "06:25", "06:40", "06:55", "07:10", "07:28", "07:45", "08:04", "08:22", "08:42", "09:01", "09:20", "09:39", "10:00", "10:20", "10:40", "11:00", "11:19", "11:43", "12:03", "12:21", "12:40", "12:59", "13:18", "13:37", "13:56", "14:16", "14:34", "14:53", "15:13", "15:29", "15:48", "16:07", "16:25", "16:45", "17:04", "17:23", "17:42", "18:01", "18:20", "18:39", "18:58", "19:18", "19:37", "19:56", "20:15", "20:34", "20:53", "21:11", "21:30", "21:49"],
    "Fri": ["04:55", "05:10", "05:25", "05:40", "05:55", "06:10", "06:25", "06:40", "06:55", "07:10", "07:27", "07:45", "08:03", "08:22", "08:41", "09:00", "09:20", "09:39", "10:00", "10:20", "10:40", "11:00", "11:20", "11:43", "12:02", "12:21", "12:40", "12:59", "13:18", "13:38", "13:56", "14:15", "14:34", "14:53", "15:12", "15:28", "15:48", "16:07", "16:26", "16:45", "17:04", "17:23", "17:42", "18:01", "18:20", "18:39", "18:57", "19:18", "19:36", "19:55", "20:14", "20:34", "20:53", "21:12", "21:30", "21:50"],
    "Sat": ["04:55", "05:12", "05:29", "05:46", "06:03", "06:20", "06:39", "06:55", "07:12", "07:30", "07:46", "08:04", "08:24", "08:47", "09:09", "09:31", "09:53", "10:14", "10:36", "10:59", "11:21", "11:43", "12:05", "12:26", "12:49", "13:11", "13:33", "13:55", "14:17", "14:38", "14:59", "15:16", "15:32", "15:52", "16:12", "16:34", "16:57", "17:18", "17:40", "18:02", "18:23", "18:44", "19:07", "19:26", "19:46", "20:07", "20:26", "20:47", "21:07", "21:28", "21:49"],
    "Holiday": ["04:55", "05:14", "05:33", "05:52", "06:12", "06:32", "06:50", "07:10", "07:29", "07:48", "08:07", "08:33", "08:58", "09:24", "09:49", "10:15", "10:38", "11:00", "11:21", "11:41", "12:06", "12:31", "12:56", "13:22", "13:47", "14:13", "14:36", "14:58", "15:19", "15:39", "16:04", "16:29", "16:54", "17:20", "17:45", "18:11", "18:34", "18:56", "19:16", "19:37", "19:56", "20:17", "20:40", "21:02", "21:25", "21:49"],
}

_BUS_190_KMOU_MAIN_WEEKDAY_SCHEDULE_SIMPLE: List[str] = [
    "04:55",
    "05:10", "05:25", "05:40", "05:55",
    "06:10", "06:25", "06:40", "06:55",
    "07:10", "07:27", "07:45",
    "08:04", "08:23", "08:42",
    "09:01", "09:20", "09:40",
    "10:00", "10:20", "10:40",
    "11:00", "11:20", "11:43",
    "12:02", "12:21", "12:40", "12:59",
    "13:18", "13:37", "13:56",
    "14:15", "14:34", "14:54",
    "15:12", "15:29", "15:47",
    "16:07", "16:26", "16:45",
    "17:04", "17:23", "17:42",
    "18:01", "18:19", "18:39", "18:57",
    "19:18", "19:37", "19:56",
    "20:14", "20:34", "20:53",
    "21:12", "21:30", "21:49"
]

async def get_bus_190_kmou_main_next_departures(now_hhmm: Optional[str] = None, date_yyyymmdd: Optional[str] = None) -> str:
    import pytz

    kst = pytz.timezone("Asia/Seoul")
    now_dt = datetime.now(kst)
    if date_yyyymmdd:
        digits = re.sub(r"\D+", "", str(date_yyyymmdd))
        if len(digits) == 8:
            try:
                dt_naive = datetime(int(digits[0:4]), int(digits[4:6]), int(digits[6:8]), now_dt.hour, now_dt.minute)
                now_dt = kst.localize(dt_naive)
            except Exception:
                pass
    if now_hhmm:
        mm = _hhmm_to_minutes(now_hhmm)
        if mm is not None:
            now_dt = now_dt.replace(hour=mm // 60, minute=mm % 60, second=0, microsecond=0)

    day_key = "Weekday"
    times = _BUS_190_KMOU_MAIN_WEEKDAY_SCHEDULE_SIMPLE[:]
    cur_m = now_dt.hour * 60 + now_dt.minute
    minutes = []
    for t in times:
        m = _hhmm_to_minutes(t)
        if m is not None:
            minutes.append((m, t))
    minutes.sort(key=lambda x: x[0])

    next1 = next(((m, t) for (m, t) in minutes if m > cur_m), None)
    if not next1:
        last = minutes[-1][1] if minutes else None
        return json.dumps(
            {
                "status": "ENDED",
                "stop_name": "í•´ì–‘ëŒ€êµ¬ë³¸ê´€",
                "route_number": "190",
                "day_type": day_key,
                "now": now_dt.strftime("%H:%M"),
                "next": None,
                "next2": None,
                "remaining_min": None,
                "last_time": last,
            },
            ensure_ascii=False,
        )

    rem1 = int(next1[0] - cur_m)
    idx = 0
    for i, (m, t) in enumerate(minutes):
        if t == next1[1] and m == next1[0]:
            idx = i
            break
    next2 = minutes[idx + 1] if idx + 1 < len(minutes) else None
    rem2 = int(next2[0] - cur_m) if next2 else None

    status = "PRE_DEPARTURE" if rem1 > 0 else "ACTIVE"
    return json.dumps(
        {
            "status": status,
            "stop_name": "í•´ì–‘ëŒ€êµ¬ë³¸ê´€",
            "route_number": "190",
            "day_type": day_key,
            "now": now_dt.strftime("%H:%M"),
            "next": {"time": next1[1], "remaining_min": rem1},
            "next2": ({"time": next2[1], "remaining_min": rem2} if next2 else None),
            "remaining_min": rem1,
        },
        ensure_ascii=False,
    )

# =========================
# 2-1) 190 ë²„ìŠ¤ íŠ¸ë˜ì»¤ (ARA_190_Bus_Tracker)
# - getBusLocation() ì‘ë‹µ(= items ë°°ì—´)ì„ ê²€ì¦í•˜ì—¬ ì‹¤ì‹œê°„ ìœ„ì¹˜ë¥¼ ì œê³µ
# - itemsê°€ ë¹„ì—ˆê±°ë‚˜(ë˜ëŠ” ì¢Œí‘œ ëˆ„ë½) ê²€ì¦ ë¶ˆê°€ì´ë©´ ì¶œë°œ(ìš´í–‰) ì‹œê°„í‘œ ë¡œì§ìœ¼ë¡œ í´ë°±
# =========================

# ìš´í–‰ ì‹œê°„(ì²«ì°¨/ë§‰ì°¨) â€” ê³µê°œ ì •ë³´ ê¸°ë°˜ ê¸°ë³¸ê°’(í™˜ê²½ë³€ìˆ˜ë¡œ ì˜¤ë²„ë¼ì´ë“œ ê°€ëŠ¥)
_BUS_190_FIRST_BUS_HHMM = (os.environ.get("ARA_BUS_190_FIRST_BUS_HHMM") or "04:55").strip()
_BUS_190_LAST_BUS_HHMM = (os.environ.get("ARA_BUS_190_LAST_BUS_HHMM") or "21:49").strip()

# ì‹¤ì‹œê°„ ìœ„ì¹˜ API(í”„ë¡œì íŠ¸ ì™¸ë¶€ ì—°ë™ìš©)
# - ì´ ë ˆí¬ì—ëŠ” "ë¶€ì‚° BIMS ì°¨ëŸ‰ë³„ GPS" ê³µì‹ ì—”ë“œí¬ì¸íŠ¸ê°€ í¬í•¨ë˜ì–´ ìˆì§€ ì•Šì•„, URL/íŒŒë¼ë¯¸í„°ëŠ” í™˜ê²½ë³€ìˆ˜ë¡œ ì£¼ì…í•©ë‹ˆë‹¤.
_BUS_190_LOCATION_URL = (os.environ.get("ARA_BUS_190_LOCATION_URL") or "").strip()
_BUS_190_LOCATION_TIMEOUT_SECONDS = float(os.environ.get("ARA_BUS_190_LOCATION_TIMEOUT_SECONDS") or "2.5")
_BUS_190_LOCATION_AUTH = (os.environ.get("ARA_BUS_190_LOCATION_AUTH") or "").strip()  # ì˜ˆ: "Bearer xxx"
_BUS_190_LOCATION_PARAMS_JSON = (os.environ.get("ARA_BUS_190_LOCATION_PARAMS_JSON") or "").strip()  # ì˜ˆ: {"routeNo":"190"}

# 190ë²ˆ ì£¼ìš” ì •ë¥˜ì¥ëª…(ê²€ì¦ìš©) â€” ê³µê°œëœ ë…¸ì„  ì•ˆë‚´(ì›¹)ì—ì„œ í™•ë³´í•œ "ì£¼ìš” ì •ë¥˜ì¥" ê¸°ë°˜
# NOTE: ì‹¤ì œ APIì˜ bstopNm í‘œê¸°ëŠ” ê´„í˜¸/ì¤‘ì /ê³µë°± ë“±ì´ ë‹¤ë¥¼ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì •ê·œí™” ë¹„êµí•©ë‹ˆë‹¤.
_ROUTE_190_STATIONS_KO: List[str] = [
    "í•´ì–‘ëŒ€êµ¬ë³¸ê´€",
    "í•´ì–‘ëŒ€ë°©íŒŒì œì…êµ¬",
    "í•´ì–‘ëŒ€ìŠ¹ì„ ìƒí™œê´€",
    "í•´ì–‘ëŒ€ì…êµ¬",
    "ì—ë´ê¸ˆí˜¸ì•„íŒŒíŠ¸",
    "ë™ì‚¼í˜ì‹ ì§€êµ¬ì…êµ¬",
    "ë™ì‚¼êµ­ë¯¼ì€í–‰ì•êµì°¨ë¡œ",
    "ë™ì‚¼ì‹œì¥",
    "ì¼ë™ë¯¸ë¼ì£¼ì•„íŒŒíŠ¸",
    "ë™ì‚¼ì‚¼ê±°ë¦¬",
    "ë™ì‚¼ì£¼ê³µ",
    "ì˜ë„êµ¬ì²­",
    "ì²­í•™ì£¼ìœ ì†Œ",
    "ì²­í•™ë™ë¶€ì‚°ì€í–‰",
    "SKë¶€ì‚°ì €ìœ ì†Œ",
    "HJì¤‘ê³µì—…",
    "í•œì„±ë§¨ì…˜",
    "êµí†µìˆœì°°ëŒ€ ì„¼íŠ¸ëŸ´ì—ì¼ë¦°ì˜ëœ°",
    "êµí†µìˆœì°°ëŒ€Â·ì„¼íŠ¸ëŸ´ ì—ì¼ë¦°ì˜ëœ°",
    "í•´ë™ë³‘ì›",
    "ì˜ë„ìš°ì²´êµ­",
    "ëŒ€êµë™",
    "ì˜ë„ëŒ€êµ ë‚¨í¬ì—­",
    "ì˜ë„ëŒ€êµÂ·ë‚¨í¬ì—­",
    "ë¶€ì‚°ë°íŒŒíŠ¸",
    "ì¤‘ì•™ì—­ ë¶€ì‚°ìš°ì²´êµ­",
    "ì¤‘ì•™ì—­Â·ë¶€ì‚°ìš°ì²´êµ­",
    "ì˜ì£¼ë™",
    "ë¶€ì‚°ì—­",
    "ì´ˆëŸ‰ì‹œì¥ì…êµ¬",
    "ë¶€ì‚°ê³ êµ",
    "í™”ì‹ ì•„íŒŒíŠ¸",
    "ë™ì¼íŒŒí¬ë§¨ì…˜",
    "ì˜ì£¼ì‚¼ê±°ë¦¬",
    "ì‹œë¯¼ì•„íŒŒíŠ¸",
]

def _norm_bstop_name(name: str) -> str:
    s = str(name or "")
    # ê´„í˜¸ ë‚´ìš© ì œê±°(ì˜ˆ: "í•´ì–‘ëŒ€ì…êµ¬(ë‚¨í¬/ì‹œë‚´í–‰)" â†’ "í•´ì–‘ëŒ€ì…êµ¬")
    s = re.sub(r"\([^)]*\)", "", s)
    # ì¤‘ì /êµ¬ë¶„ì ì œê±°
    s = s.replace("Â·", " ").replace("â€¢", " ")
    # ê³µë°± ì œê±°
    s = re.sub(r"\s+", "", s)
    # í•œê¸€/ì˜ë¬¸/ìˆ«ìë§Œ ë‚¨ê¹€(ë¹„êµ ì•ˆì •í™”)
    s = re.sub(r"[^0-9A-Za-zê°€-í£_]", "", s)
    return s.lower()

_ROUTE_190_STATIONS_NORM = {_norm_bstop_name(x) for x in _ROUTE_190_STATIONS_KO if x}

def _as_float(v: Any) -> Optional[float]:
    if v is None:
        return None
    try:
        return float(str(v).strip())
    except Exception:
        return None

def _extract_items_from_bus_location_payload(payload: Any) -> List[Dict[str, Any]]:
    """
    getBusLocation() ì‘ë‹µì—ì„œ items ë°°ì—´ ì¶”ì¶œ.
    - ìš”êµ¬ì‚¬í•­: API 'items' array ê²€ì¦. ë¹„ì—ˆê±°ë‚˜ Noneì´ë©´ [] ë°˜í™˜.
    """
    if payload is None:
        return []
    if isinstance(payload, str):
        try:
            payload = json.loads(payload)
        except Exception:
            return []
    if not isinstance(payload, dict):
        return []

    items = payload.get("items", None)
    # í”í•œ ì¤‘ì²© ì¼€ì´ìŠ¤ë„ ë³´ìˆ˜ì ìœ¼ë¡œ ì§€ì›
    if items is None:
        items = _safe_get(payload, "response", "body", "items", default=None)
    if items is None:
        items = _safe_get(payload, "response", "body", "items", "item", default=None)

    # ë‹¨ì¼ dict â†’ listë¡œ ìŠ¹ê²©
    if isinstance(items, dict):
        if "item" in items and isinstance(items.get("item"), list):
            items = items.get("item")
        else:
            items = [items]
    if items is None:
        return []
    if not isinstance(items, list):
        return []
    out: List[Dict[str, Any]] = []
    for it in items:
        if isinstance(it, dict):
            out.append(it)
    return out

async def _get_bus_190_location_api_payload() -> Any:
    """
    ì™¸ë¶€ ìœ„ì¹˜ API í˜¸ì¶œ.
    - ì´ ë ˆí¬ì—ì„œëŠ” URL/íŒŒë¼ë¯¸í„°ë¥¼ ê°•ì œí•˜ì§€ ì•Šê³  í™˜ê²½ë³€ìˆ˜ë¡œë§Œ ì£¼ì…í•©ë‹ˆë‹¤.
    - URLì´ ì—†ìœ¼ë©´ items=[]ë¡œ ì·¨ê¸‰ë˜ì–´ ì‹œê°„í‘œ í´ë°±ìœ¼ë¡œ ì§„í–‰ë©ë‹ˆë‹¤.
    """
    if not _BUS_190_LOCATION_URL:
        return {"items": []}

    params: Dict[str, Any] = {}
    if _BUS_190_LOCATION_PARAMS_JSON:
        try:
            parsed = json.loads(_BUS_190_LOCATION_PARAMS_JSON)
            if isinstance(parsed, dict):
                params = parsed
        except Exception:
            params = {}

    extra_headers: Dict[str, str] = {}
    if _BUS_190_LOCATION_AUTH:
        extra_headers["Authorization"] = _BUS_190_LOCATION_AUTH

    try:
        async with httpx.AsyncClient(verify=HTTPX_VERIFY, headers={**HEADERS, **extra_headers}) as client:
            res = await client.get(_BUS_190_LOCATION_URL, params=params, timeout=_BUS_190_LOCATION_TIMEOUT_SECONDS)
        res.raise_for_status()
        # JSON ìš°ì„ 
        try:
            return res.json()
        except Exception:
            # JSONì´ ì•„ë‹ˆë©´ ì•ˆì „í•˜ê²Œ ì‹¤íŒ¨ ì²˜ë¦¬(ì¢Œí‘œ í™˜ê° ê¸ˆì§€)
            return {"items": []}
    except Exception:
        return {"items": []}

def _bus_190_departure_schedule_payload(now_dt: datetime) -> Dict[str, Any]:
    """
    itemsê°€ ì—†ì„ ë•Œì˜ í´ë°±(ìš´í–‰ ì‹œê°„í‘œ/ìš´í–‰ì¢…ë£Œ íŒë‹¨).
    - anti_hallucination_rules: current_time > last_bus_time â†’ SERVICE_ENDED
    """
    first_m = _hhmm_to_minutes(_BUS_190_FIRST_BUS_HHMM)
    last_m = _hhmm_to_minutes(_BUS_190_LAST_BUS_HHMM)
    cur_m = now_dt.hour * 60 + now_dt.minute

    # ì•ˆì „ì¥ì¹˜: ì‹œê°„í‘œ íŒŒì‹± ì‹¤íŒ¨ ì‹œ ë³´ìˆ˜ì ìœ¼ë¡œ "í™•ì¸ ì¤‘"
    if first_m is None or last_m is None:
        return {
            "status": "ACTIVE",
            "data": {
                "bus_id": None,
                "location": {"lat": None, "lng": None},
                "remaining_time": None,
                "message": "DEPARTURE_SCHEDULE: 190ë²ˆ ë²„ìŠ¤ ìš´í–‰ ì‹œê°„í‘œ ë°ì´í„°ê°€ ì˜¬ë°”ë¥´ì§€ ì•Šì•„ í™•ì¸ ì¤‘ì…ë‹ˆë‹¤.",
            },
        }

    if cur_m > last_m:
        return {
            "status": "ENDED",
            "data": {
                "bus_id": None,
                "location": {"lat": None, "lng": None},
                "remaining_time": None,
                "message": "SERVICE_ENDED",
            },
        }

    if cur_m < first_m:
        remain = first_m - cur_m
        return {
            "status": "PRE_DEPARTURE",
            "data": {
                "bus_id": None,
                "location": {"lat": None, "lng": None},
                "remaining_time": f"{remain}ë¶„",
                "message": f"DEPARTURE_SCHEDULE: ì²«ì°¨({_BUS_190_FIRST_BUS_HHMM})ê¹Œì§€ ì•½ {remain}ë¶„ ë‚¨ì•˜ìŠµë‹ˆë‹¤. (ë§‰ì°¨ {_BUS_190_LAST_BUS_HHMM})",
            },
        }

    # ìš´í–‰ ì‹œê°„ ë‚´ì´ì§€ë§Œ ìœ„ì¹˜ ë°ì´í„°ê°€ ì—†ì„ ìˆ˜ ìˆìŒ(ì°¨ê³ ì§€ ëŒ€ê¸°/ì„œë²„ ë¯¸ì‘ë‹µ ë“±)
    return {
        "status": "ACTIVE",
        "data": {
            "bus_id": None,
            "location": {"lat": None, "lng": None},
            "remaining_time": None,
            "message": f"DEPARTURE_SCHEDULE: í˜„ì¬ ì‹¤ì‹œê°„ ìœ„ì¹˜ ë°ì´í„°(items)ê°€ ì—†ì–´ ìš´í–‰ ì‹œê°„ë§Œ ì•ˆë‚´í•©ë‹ˆë‹¤. (ì²«ì°¨ {_BUS_190_FIRST_BUS_HHMM} / ë§‰ì°¨ {_BUS_190_LAST_BUS_HHMM})",
        },
    }

async def get_bus_190_tracker(now_hhmm: Optional[str] = None, date_yyyymmdd: Optional[str] = None) -> str:
    """
    ARA_190_Bus_Tracker
    - step_1: getBusLocation() ì‘ë‹µ íŒŒì‹±
    - step_2:
      - items ì¡´ì¬ + ì¢Œí‘œ ìœ íš¨: REAL_TIME_TRACKING
      - items ë¹„ì–´ìˆìŒ/ë¬´íš¨: DEPARTURE_SCHEDULE(ìš´í–‰ì‹œê°„/ìš´í–‰ì¢…ë£Œ)
    ë°˜í™˜: output_template ì¤€ìˆ˜(JSON ë¬¸ìì—´)
    """
    # ê¸°ì¤€ ì‹œê°(KST, í…ŒìŠ¤íŠ¸ ì˜¤ë²„ë¼ì´ë“œ ì§€ì›)
    now_dt = _reference_datetime()
    if date_yyyymmdd:
        digits = re.sub(r"\D+", "", str(date_yyyymmdd))
        if len(digits) == 8:
            try:
                now_dt = datetime(int(digits[0:4]), int(digits[4:6]), int(digits[6:8]), now_dt.hour, now_dt.minute, tzinfo=_KST)
            except Exception:
                pass
    if now_hhmm:
        mm = _hhmm_to_minutes(now_hhmm)
        if mm is not None:
            now_dt = now_dt.replace(hour=mm // 60, minute=mm % 60, second=0, microsecond=0)

    payload = await _get_bus_190_location_api_payload()
    items = _extract_items_from_bus_location_payload(payload)

    # items ê²€ì¦ ì‹¤íŒ¨/ë¹ˆ ë°°ì—´ â†’ ì‹œê°„í‘œ í´ë°±
    if not items:
        return json.dumps(_bus_190_departure_schedule_payload(now_dt), ensure_ascii=False)

    # itemsê°€ ìˆì–´ë„ ì¢Œí‘œê°€ null/íŒŒì‹± ë¶ˆê°€ì´ë©´ í™˜ê° ê¸ˆì§€ â†’ ì‹œê°„í‘œ í´ë°±
    candidates: List[Dict[str, Any]] = []
    for it in items:
        lat = _as_float(it.get("lat") if isinstance(it, dict) else None)
        lon = _as_float(it.get("lon") if isinstance(it, dict) else None)
        if lat is None:
            lat = _as_float(it.get("latitude") if isinstance(it, dict) else None)
        if lon is None:
            lon = _as_float(it.get("lng") if isinstance(it, dict) else None)
        if lon is None:
            lon = _as_float(it.get("longitude") if isinstance(it, dict) else None)

        if lat is None or lon is None:
            continue

        car_no = (it.get("carNo") or it.get("car_no") or it.get("bus_id") or it.get("id")) if isinstance(it, dict) else None
        bstop_nm = (it.get("bstopNm") or it.get("bstopnm") or it.get("stopName") or it.get("bstop_name")) if isinstance(it, dict) else None

        verified_stop = False
        if bstop_nm:
            verified_stop = _norm_bstop_name(str(bstop_nm)) in _ROUTE_190_STATIONS_NORM

        candidates.append(
            {
                "lat": float(lat),
                "lon": float(lon),
                "carNo": str(car_no) if car_no is not None else None,
                "bstopNm": str(bstop_nm) if bstop_nm is not None else None,
                "verified_stop": bool(verified_stop),
            }
        )

    if not candidates:
        return json.dumps(_bus_190_departure_schedule_payload(now_dt), ensure_ascii=False)

    # ê²€ì¦ëœ ì •ë¥˜ì¥ëª…ì„ ìš°ì„  ì„ íƒ(ì—†ìœ¼ë©´ ì²« í›„ë³´)
    picked = next((c for c in candidates if c.get("verified_stop") is True), candidates[0])
    ver_txt = "OK" if picked.get("verified_stop") else "FAIL"
    stop_txt = picked.get("bstopNm") or "ì•Œ ìˆ˜ ì—†ìŒ"
    bus_id = picked.get("carNo")

    out = {
        "status": "ACTIVE",
        "data": {
            "bus_id": bus_id,
            "location": {"lat": picked["lat"], "lng": picked["lon"]},
            "remaining_time": None,
            "message": f"REAL_TIME_TRACKING: ì°¨ëŸ‰ {bus_id or 'ë¯¸ìƒ'} / ì •ë¥˜ì¥ {stop_txt} (ì •ë¥˜ì¥ëª… ê²€ì¦: {ver_txt})",
        },
    }
    return json.dumps(out, ensure_ascii=False)

async def get_bus_190_tracker_busbusinfo(line_id: str = "5200190000", kmou_stop_id: str = "04001") -> str:
    import xml.etree.ElementTree as ET

    now_dt = _reference_datetime()
    last_updated = now_dt.isoformat(timespec="seconds")

    if not DATA_GO_KR_SERVICE_KEY:
        return json.dumps(
            {
                "status": "ENDED",
                "realtime_buses": [],
                "departure_info": {"eta_minutes": None, "message": "ì •ë³´ ì—†ìŒ"},
                "last_updated": last_updated,
            },
            ensure_ascii=False,
        )

    loc_url = "http://apis.data.go.kr/6260000/BusBusInfoService/getBusLocationList"
    arr_url = "http://apis.data.go.kr/6260000/BusBusInfoService/getBusArrivalList"
    timeout_s = float(os.environ.get("ARA_BUS_190_TIMEOUT_SECONDS", "2.5"))
    start_radius_m = float(os.environ.get("ARA_BUS_190_START_RADIUS_M", "5000"))

    def _xml_ok(xml_text: str) -> bool:
        try:
            root = ET.fromstring(xml_text or "")
        except Exception:
            return False
        code = (root.findtext(".//resultCode") or "").strip()
        return code in {"00", "0"}

    def _parse_items(xml_text: str) -> List[Dict[str, str]]:
        try:
            root = ET.fromstring(xml_text or "")
        except Exception:
            return []
        out: List[Dict[str, str]] = []
        for items_el in root.findall(".//items"):
            for it in items_el.findall("./item"):
                d: Dict[str, str] = {}
                for child in list(it):
                    if child.tag and child.text is not None:
                        d[child.tag] = child.text
                if d:
                    out.append(d)
            if out:
                break
        return out

    def _pick_first(d: Dict[str, Any], keys: List[str]) -> Optional[str]:
        for k in keys:
            v = d.get(k)
            if v is None:
                continue
            s = str(v).strip()
            if s:
                return s
        return None

    async def _call_xml(url: str, params: Dict[str, Any]) -> str:
        async with httpx.AsyncClient(verify=HTTPX_VERIFY, headers=HEADERS) as client:
            res = await client.get(url, params=params, timeout=timeout_s)
        res.raise_for_status()
        return res.text or ""

    async def _fetch_locations() -> List[Dict[str, Any]]:
        line = (line_id or "").strip()
        if not line:
            return []
        candidates = [
            {"serviceKey": DATA_GO_KR_SERVICE_KEY, "lineId": line},
            {"serviceKey": DATA_GO_KR_SERVICE_KEY, "lineid": line},
            {"serviceKey": DATA_GO_KR_SERVICE_KEY, "line_id": line},
        ]
        xml_text = ""
        for p in candidates:
            try:
                xml_text = await _call_xml(loc_url, p)
                if _xml_ok(xml_text):
                    items = _parse_items(xml_text)
                    if items:
                        break
            except Exception:
                continue
        items = _parse_items(xml_text) if (_xml_ok(xml_text) and xml_text) else []
        buses: List[Dict[str, Any]] = []
        for it in items:
            car = _pick_first(it, ["carNo", "carno", "car_no", "vehId", "vhclNo", "busNo"])
            lat = _as_float(_pick_first(it, ["lat", "gpsLat", "y", "gpsy", "posY", "latitude"]))
            lon = _as_float(_pick_first(it, ["lng", "lon", "x", "gpsx", "posX", "longitude"]))
            if lat is None or lon is None:
                continue
            buses.append({"carNo": (car or None), "lat": float(lat), "lng": float(lon)})
        return buses

    async def _fetch_departure_eta() -> Optional[int]:
        stop_id = (kmou_stop_id or "").strip()
        if not stop_id:
            return None
        candidates = [
            {"serviceKey": DATA_GO_KR_SERVICE_KEY, "bstopid": stop_id},
            {"serviceKey": DATA_GO_KR_SERVICE_KEY, "bstopId": stop_id},
            {"serviceKey": DATA_GO_KR_SERVICE_KEY, "bstop_id": stop_id},
        ]
        xml_text = ""
        for p in candidates:
            try:
                xml_text = await _call_xml(arr_url, p)
                if _xml_ok(xml_text):
                    items = _parse_items(xml_text)
                    if items:
                        break
            except Exception:
                continue
        items = _parse_items(xml_text) if (_xml_ok(xml_text) and xml_text) else []
        if not items:
            return None

        target_line = (line_id or "").strip()
        picked: Optional[Dict[str, str]] = None
        for it in items:
            line_val = _pick_first(it, ["lineId", "lineid", "line_id", "routeId", "routeid", "route_id", "lineno", "lineNo", "routeno"])
            if target_line and line_val and str(line_val).strip() == target_line:
                picked = it
                break
        if picked is None:
            picked = items[0]

        raw_min = _pick_first(picked, ["min1", "remainMin", "remain_min", "eta", "arrtime", "arrTime", "time"])
        if not raw_min:
            return None
        digits = re.sub(r"\D+", "", str(raw_min))
        if not digits:
            return None
        try:
            return int(digits)
        except Exception:
            return None

    realtime = await _fetch_locations()
    any_near = False
    for b in realtime:
        near, _ = _is_near_kmou(b.get("lat"), b.get("lng"), radius_m=start_radius_m)
        if near:
            any_near = True
            break

    eta_min = None
    if (not realtime) or (not any_near):
        eta_min = await _fetch_departure_eta()
    else:
        eta_min = await _fetch_departure_eta()

    first_m = _hhmm_to_minutes(_BUS_190_FIRST_BUS_HHMM)
    last_m = _hhmm_to_minutes(_BUS_190_LAST_BUS_HHMM)
    cur_m = now_dt.hour * 60 + now_dt.minute

    if eta_min is not None:
        dep_msg = f"ì¶œë°œ ì˜ˆì • {eta_min}ë¶„"
    else:
        if last_m is not None and cur_m > last_m:
            dep_msg = "ìš´í–‰ ì¢…ë£Œ"
        else:
            dep_msg = "ì •ë³´ ì—†ìŒ"

    if eta_min is not None and ((not realtime) or (not any_near)):
        status = "PRE_DEPARTURE"
    elif realtime:
        status = "ACTIVE"
    else:
        status = "ENDED" if dep_msg == "ìš´í–‰ ì¢…ë£Œ" else "ENDED"

    return json.dumps(
        {
            "status": status,
            "realtime_buses": [{"carNo": b.get("carNo"), "lat": b.get("lat"), "lng": b.get("lng")} for b in realtime],
            "departure_info": {"eta_minutes": eta_min, "message": dep_msg},
            "last_updated": last_updated,
        },
        ensure_ascii=False,
    )

# =========================
# 3) ë§›ì§‘/ì˜ë£Œ (ê¸°ì¡´ ê¸°ëŠ¥ ìœ ì§€)
# =========================

def _read_places_csv(limit: int = 5) -> List[Dict[str, str]]:
    path = os.path.join(os.path.dirname(__file__), "places.csv")
    if not os.path.exists(path):
        return []

    rows: List[Dict[str, str]] = []
    with open(path, "r", encoding="utf-8-sig", newline="") as f:
        reader = csv.reader(f)
        for idx, row in enumerate(reader):
            if not row:
                continue
            if idx == 0 and row[0].strip().lower().startswith("git merge"):
                continue
            name = (row[0] if len(row) > 0 else "").strip()
            category = (row[1] if len(row) > 1 else "").strip()
            description = (row[2] if len(row) > 2 else "").strip()
            recommendation = (row[3] if len(row) > 3 else "").strip()
            if not name:
                continue
            rows.append({"name": name, "category": category, "description": description, "recommendation": recommendation})
            if len(rows) >= limit:
                break
    return rows

async def get_cheap_eats(food_type: str = "í•œì‹"):
    """
    ì˜ë„ ì°©í•œê°€ê²©/ê°€ì„±ë¹„ ì‹ë‹¹ ì¡°íšŒ
    - DATA_GO_KR_SERVICE_KEY ì—†ìœ¼ë©´ places.csvë¡œ ì œí•œ ì•ˆë‚´
    """
    if not DATA_GO_KR_SERVICE_KEY:
        places = _read_places_csv(limit=5)
        if not places:
            return json.dumps({"status": "error", "msg": "ê³µê³µë°ì´í„° API í‚¤ ë° ë¡œì»¬ ë°ì´í„°ê°€ ì—†ì–´ ì¡°íšŒí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}, ensure_ascii=False)
        return json.dumps({"status": "success", "source": "local_csv", "restaurants": places}, ensure_ascii=False)

    url = "http://apis.data.go.kr/6260000/GoodPriceStoreService/getGoodPriceStore"
    params = {"serviceKey": DATA_GO_KR_SERVICE_KEY, "numOfRows": "100", "pageNo": "1", "resultType": "json"}
    res = await _http_get_json(url, params, timeout=15.0)
    if res["status"] != "success":
        return json.dumps({"status": "error", "msg": res.get("msg", "API í˜¸ì¶œ ì‹¤íŒ¨")}, ensure_ascii=False)

    try:
        # API ì‘ë‹µ êµ¬ì¡° fail-safe (ì¼ë¶€ëŠ” response.body.items.item í˜•íƒœ)
        items = _safe_get(res, "data", "getGoodPriceStore", "item", default=None)
        if not items:
            items = _safe_get(res, "data", "response", "body", "items", "item", default=[]) or []
        if isinstance(items, dict):
            items = [items]
        targets = []
        for i in items:
            addr = (i.get("adres") or i.get("addr") or "").strip()
            if "ì˜ë„" not in addr:
                continue

            # food_typeì€ ë°ì´í„° í•„ë“œê°€ ì¼ì •ì¹˜ ì•Šì•„ ë³´ìˆ˜ì ìœ¼ë¡œ ì ìš©(ë¹„ì–´ìˆìœ¼ë©´ í•„í„° ìƒëµ)
            if food_type:
                blob = " ".join(
                    [
                        str(i.get("cn", "") or ""),
                        str(i.get("mNm", "") or ""),
                        str(i.get("sj", "") or ""),
                        _strip_html(i.get("intrcn", "") or ""),
                    ]
                )
                if food_type not in blob:
                    continue

            targets.append(
                {
                    "name": (i.get("sj") or "").strip(),
                    "addr": addr,
                    "tel": (i.get("tel") or "").strip(),
                    "time": (i.get("bsnTime") or "").strip(),
                    "desc": _strip_html(i.get("intrcn", "") or ""),
                }
            )
        if not targets:
            # ê³µê³µë°ì´í„°ì—ì„œ ì˜ë„ê¶Œ ê²°ê³¼ê°€ ì—†ìœ¼ë©´ ë¡œì»¬ CSVë¡œ graceful fallback
            places = _read_places_csv(limit=5)
            if places:
                return json.dumps(
                    {
                        "status": "success",
                        "source": "local_csv_fallback",
                        "msg": "ê³µê³µë°ì´í„°ì—ì„œ ì˜ë„êµ¬ ì°©í•œê°€ê²© ì‹ë‹¹ì„ ì¶©ë¶„íˆ í™•ì¸í•˜ì§€ ëª»í•´, ë¡œì»¬ ì¶”ì²œ ëª©ë¡ìœ¼ë¡œ ì•ˆë‚´ë“œë¦½ë‹ˆë‹¤.",
                        "restaurants": places,
                    },
                    ensure_ascii=False,
                )
            return json.dumps({"status": "empty", "msg": "ì¡°ê±´ì— ë§ëŠ” ì‹ë‹¹ ì •ë³´ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."}, ensure_ascii=False)
        return json.dumps({"status": "success", "source": "public_api", "restaurants": targets[:5]}, ensure_ascii=False)
    except Exception as e:
        return json.dumps({"status": "error", "msg": str(e)}, ensure_ascii=False)

# =========================
# 3) ë§›ì§‘(ë™ì  ì¶”ì²œ) â€” ë©€í‹°í„´ìš©
# =========================

async def search_restaurants(query: str, limit: int = 5):
    """
    ë§›ì§‘/ì¹´í˜ ë™ì  ê²€ìƒ‰(ë¬´í™˜ê°)
    - 1ìˆœìœ„: Kakao Local Search(í‚¤ê°€ ìˆì„ ë•Œë§Œ)
    - 2ìˆœìœ„: places.csv í´ë°±
    """
    q = (query or "").strip()
    if not q:
        return json.dumps({"status": "error", "msg": "ê²€ìƒ‰ì–´ê°€ í•„ìš”í•©ë‹ˆë‹¤."}, ensure_ascii=False)

    limit_n = max(1, min(int(limit or 5), 10))

    def _addr_is_yeongdo(addr: str) -> bool:
        a = (addr or "").strip()
        if not a:
            return False
        al = a.lower()
        # Kakao ì£¼ì†ŒëŠ” ë³´í†µ "ë¶€ì‚° ì˜ë„êµ¬ ..." í˜•íƒœ
        return ("ì˜ë„êµ¬" in a) or ("yeongdo-gu" in al) or ("yeongdo gu" in al) or ("yeongdo" in al and "busan" in al)

    kakao_key = (os.environ.get("KAKAO_REST_API_KEY") or "").strip()
    if kakao_key:
        try:
            url = "https://dapi.kakao.com/v2/local/search/keyword.json"
            # ì˜ë„êµ¬ ê²°ê³¼ë¥¼ ìœ ë„(ê²€ìƒ‰ ì¿¼ë¦¬ë§Œ ë³´ê°•; ê²°ê³¼ëŠ” ì¢Œí‘œ/ì£¼ì†Œë¡œ ì¬ê²€ì¦)
            query2 = f"{q} ì˜ë„êµ¬"
            # ì˜ë„êµ¬ ì „ì²´ë¥¼ ì»¤ë²„í•˜ë„ë¡ ë°˜ê²½ í™•ëŒ€(ì¤‘ì‹¬: KMOU)
            radius_m = int(os.environ.get("ARA_KAKAO_YEONGDO_RADIUS_M", "20000"))
            radius_m = max(1000, min(radius_m, 20000))
            async with httpx.AsyncClient(verify=HTTPX_VERIFY, headers={"Authorization": f"KakaoAK {kakao_key}"}) as client:
                # í•„í„°ë§ìœ¼ë¡œ 0ê±´ì´ ë  ìˆ˜ ìˆì–´ sizeëŠ” ì—¬ìœ  ìˆê²Œ ìš”ì²­
                res = await client.get(
                    url,
                    params={
                        "query": query2,
                        "x": str(_KMOU_LON),
                        "y": str(_KMOU_LAT),
                        "radius": str(radius_m),
                        "size": "15",
                    },
                    timeout=2.5,
                )
                res.raise_for_status()
                data = res.json()

            docs = (data.get("documents") or []) if isinstance(data, dict) else []
            out: List[Dict[str, Any]] = []
            for d in docs:
                name = (d.get("place_name") or "").strip()
                addr = (d.get("road_address_name") or d.get("address_name") or "").strip()
                phone = (d.get("phone") or "").strip()
                link = (d.get("place_url") or "").strip()
                try:
                    lon = float(d.get("x")) if d.get("x") else None
                    lat = float(d.get("y")) if d.get("y") else None
                except Exception:
                    lat, lon = None, None

                # ì§€ì˜¤íœì‹±(ìš”êµ¬ì‚¬í•­): ë¶€ì‚°ê´‘ì—­ì‹œ ì˜ë„êµ¬ ë‚´ë§Œ í—ˆìš© (ì¢Œí‘œëŠ” ê²€ìƒ‰/í•„í„°ì—ë§Œ ì‚¬ìš©)
                near, dist_m = _is_near_kmou(lat, lon, radius_m=float(radius_m))
                if not near:
                    continue
                if not _addr_is_yeongdo(addr):
                    continue

                out.append(
                    {
                        "name": name,
                        "addr": addr,
                        "tel": phone,
                        "lat": lat,
                        "lon": lon,
                        "distance_m": dist_m,
                        "link": link,
                        "source": "kakao",
                    }
                )
                if len(out) >= limit_n:
                    break

            if out:
                return json.dumps({"status": "success", "query": q, "restaurants": out}, ensure_ascii=False)
        except Exception:
            # Kakao API ì‹¤íŒ¨ ì‹œ places.csv í´ë°±ìœ¼ë¡œ ì§„í–‰(ì¶”ì¸¡ ê¸ˆì§€)
            pass

    # places.csv í´ë°±(ì¢Œí‘œ ì—†ìŒ â†’ í…ìŠ¤íŠ¸ ê¸°ë°˜ìœ¼ë¡œ 'ì˜ë„/í•´ì–‘ëŒ€' ê·¼ì²˜ë§Œ í†µê³¼)
    try:
        path = os.path.join(os.path.dirname(__file__), "places.csv")
        if not os.path.exists(path):
            # ìµœí›„ í´ë°±: ìŠ¹ì¸ëœ ì‚¬ìš©ì ì œë³´(ê´€ë¦¬ì ê²€ìˆ˜ í›„)ì—ì„œë§Œ ê²€ìƒ‰
            try:
                from database import search_approved_contributions
                contrib = search_approved_contributions(q, limit=limit_n)
                if contrib:
                    return json.dumps({"status": "success", "query": q, "restaurants": contrib}, ensure_ascii=False)
            except Exception:
                pass
            return json.dumps({"status": "empty", "msg": "ë¡œì»¬ places.csvë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."}, ensure_ascii=False)

        with open(path, "r", encoding="utf-8", newline="") as f:
            reader = csv.DictReader(f)
            # í—¤ë”ì— ë¨¸ì§€ ì°Œêº¼ê¸°ê°€ ì„ì¸ ê²½ìš° ë°©ì–´
            fieldnames = reader.fieldnames or []
            if fieldnames and fieldnames[0].lower().startswith("git merge"):
                # ì²« ì»¬ëŸ¼ëª…ì„ nameìœ¼ë¡œ ì •ê·œí™”
                fieldnames[0] = "name"
                reader.fieldnames = fieldnames

            rows = list(reader)

        ql = q.lower()
        out: List[Dict[str, Any]] = []
        for r in rows:
            name = (r.get("name") or r.get("temp-fixname") or "").strip()
            cat = (r.get("category") or "").strip()
            desc = (r.get("description") or "").strip()
            rec = (r.get("recommendation") or "").strip()

            blob = f"{name} {cat} {desc} {rec}".lower()
            if ql not in blob:
                continue

            # ìœ„ì¹˜ ê·¼ê±°ê°€ í…ìŠ¤íŠ¸ì— í¬í•¨ë  ë•Œë§Œ í†µê³¼(ë¬´í™˜ê°)
            # - ì¢Œí‘œê°€ ì—†ìœ¼ë¯€ë¡œ 'ì˜ë„/í•´ì–‘ëŒ€' ë“± ê·¼ê±° ë¬¸ìì—´ì´ ì—†ìœ¼ë©´ íê¸°
            if not any(k in desc for k in ["ì˜ë„êµ¬", "ì˜ë„", "í•´ì–‘ëŒ€", "ë™ì‚¼ë™", "í°ì—¬ìš¸"]):
                continue

            out.append({"name": name, "category": cat, "description": desc, "recommendation": rec, "source": "places.csv"})
            if len(out) >= limit_n:
                break

        if not out:
            # ìµœí›„ í´ë°±: ìŠ¹ì¸ëœ ì‚¬ìš©ì ì œë³´(ê´€ë¦¬ì ê²€ìˆ˜ í›„)ì—ì„œë§Œ ê²€ìƒ‰
            try:
                from database import search_approved_contributions
                contrib = search_approved_contributions(q, limit=limit_n)
                if contrib:
                    return json.dumps({"status": "success", "query": q, "restaurants": contrib}, ensure_ascii=False)
            except Exception:
                pass
            return json.dumps({"status": "empty", "msg": "ì¡°ê±´ì— ë§ëŠ” ë¶€ì‚°ê´‘ì—­ì‹œ ì˜ë„êµ¬ ë§›ì§‘ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."}, ensure_ascii=False)
        return json.dumps({"status": "success", "query": q, "restaurants": out}, ensure_ascii=False)
    except Exception as e:
        return json.dumps({"status": "error", "msg": str(e)}, ensure_ascii=False)

async def get_random_yeongdo_restaurant(limit_pool: int = 15) -> str:
    import random

    kakao_key = (os.environ.get("KAKAO_REST_API_KEY") or "").strip()
    limit_n = max(5, min(int(limit_pool or 15), 15))

    def _is_cafe_blob(name: str, cat: str) -> bool:
        blob = f"{name} {cat}".lower()
        return ("ì¹´í˜" in blob) or ("ì»¤í”¼" in blob) or ("cafe" in blob) or ("coffee" in blob)

    if kakao_key:
        try:
            url = "https://dapi.kakao.com/v2/local/search/keyword.json"
            headers = {"Authorization": f"KakaoAK {kakao_key}"}
            async with httpx.AsyncClient(verify=HTTPX_VERIFY, headers=headers) as client:
                res = await client.get(
                    url,
                    params={
                        "query": "ì˜ë„êµ¬ ë§›ì§‘",
                        "x": str(_KMOU_LON),
                        "y": str(_KMOU_LAT),
                        "radius": str(max(1000, min(int(os.environ.get("ARA_KAKAO_YEONGDO_RADIUS_M", "20000")), 20000))),
                        "size": str(limit_n),
                    },
                    timeout=2.5,
                )
            res.raise_for_status()
            data = res.json() if res is not None else {}
            docs = (data.get("documents") or []) if isinstance(data, dict) else []
            candidates: List[Dict[str, Any]] = []
            for d in docs:
                name = (d.get("place_name") or "").strip()
                addr = (d.get("road_address_name") or d.get("address_name") or "").strip()
                phone = (d.get("phone") or "").strip()
                link = (d.get("place_url") or "").strip()
                cat = (d.get("category_name") or d.get("category_group_name") or "").strip()
                if addr and ("ì˜ë„êµ¬" not in addr) and ("ì˜ë„" not in addr):
                    continue
                if _is_cafe_blob(name, cat):
                    continue
                if not name:
                    continue
                candidates.append({"name": name, "addr": addr, "tel": phone, "link": link, "source": "kakao"})
            if candidates:
                picked = random.choice(candidates)
                return json.dumps({"status": "success", "restaurant": picked}, ensure_ascii=False)
        except Exception:
            pass

    try:
        path = os.path.join(os.path.dirname(__file__), "places.csv")
        if not os.path.exists(path):
            return json.dumps({"status": "empty", "msg": "ì •ë³´ ì—†ìŒ"}, ensure_ascii=False)
        with open(path, "r", encoding="utf-8", newline="") as f:
            reader = csv.DictReader(f)
            rows = list(reader)
        candidates = []
        for r in rows:
            name = (r.get("name") or r.get("temp-fixname") or "").strip()
            cat = (r.get("category") or "").strip()
            desc = (r.get("description") or "").strip()
            rec = (r.get("recommendation") or "").strip()
            if not name:
                continue
            if _is_cafe_blob(name, cat):
                continue
            if not any(k in (desc or "") for k in ["ì˜ë„êµ¬", "ì˜ë„", "í•´ì–‘ëŒ€", "ë™ì‚¼ë™", "í°ì—¬ìš¸"]):
                continue
            candidates.append({"name": name, "addr": desc, "tel": "", "link": "", "source": "places.csv", "recommendation": rec})
        if not candidates:
            return json.dumps({"status": "empty", "msg": "ì •ë³´ ì—†ìŒ"}, ensure_ascii=False)
        picked = random.choice(candidates)
        return json.dumps({"status": "success", "restaurant": picked}, ensure_ascii=False)
    except Exception:
        return json.dumps({"status": "empty", "msg": "ì •ë³´ ì—†ìŒ"}, ensure_ascii=False)

async def get_worknet_maritime_logistics_jobs(query: Optional[str] = None, limit: int = 5, lang: str = "ko") -> str:
    import requests
    import xml.etree.ElementTree as ET
    from urllib.parse import quote

    lang = (lang or "ko").strip().lower()
    if lang not in {"ko", "en"}:
        lang = "ko"

    auth_key = (os.environ.get("WORKNET_API_KEY") or os.environ.get("WORKNET_AUTH_KEY") or "").strip()
    if not auth_key:
        return json.dumps(
            {"status": "error", "msg": ("ì •ë³´ë¥¼ í™•ì¸ ì¤‘ì…ë‹ˆë‹¤" if lang != "en" else "Data is being verified.")},
            ensure_ascii=False,
        )

    q = (query or "").strip()
    if not q:
        q = "í•´ìš´ ë¬¼ë¥˜"

    url = "http://openapi.work.go.kr/opi/opi/opia/wantedApi.do"
    timeout_s = float(os.environ.get("ARA_WORKNET_TIMEOUT_SECONDS", "3.5"))
    display = str(max(5, min(int(limit or 5) * 3, 30)))
    params = {
        "authKey": auth_key,
        "callTp": "L",
        "returnType": "XML",
        "startPage": "1",
        "display": display,
        "keyword": q,
    }

    def _fetch_xml() -> str:
        r = requests.get(url, params=params, headers=HEADERS, timeout=timeout_s, verify=HTTPX_VERIFY)
        r.raise_for_status()
        return r.text or ""

    try:
        xml_text = await asyncio.to_thread(_fetch_xml)
    except Exception:
        return json.dumps(
            {"status": "error", "msg": ("í˜„ì¬ ì±„ìš© ì •ë³´ë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤." if lang != "en" else "Unable to fetch job listings right now.")},
            ensure_ascii=False,
        )

    try:
        root = ET.fromstring(xml_text)
    except Exception:
        return json.dumps(
            {"status": "error", "msg": ("í˜„ì¬ ì±„ìš© ì •ë³´ë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤." if lang != "en" else "Unable to fetch job listings right now.")},
            ensure_ascii=False,
        )

    def _txt(path: str) -> str:
        return (root.findtext(path) or "").strip()

    code = _txt(".//resultCode")
    if code and code not in {"00", "0"}:
        return json.dumps(
            {"status": "error", "msg": ("í˜„ì¬ ì±„ìš© ì •ë³´ë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤." if lang != "en" else "Unable to fetch job listings right now.")},
            ensure_ascii=False,
        )

    keywords = ["í•´ìš´", "í•­ë§Œ", "ë¬¼ë¥˜", "í¬ì›Œë”©", "ì„ ì‚¬", "í•´ìƒ", "maritime", "logistics", "shipping", "port"]
    out: List[Dict[str, Any]] = []

    for it in root.findall(".//wanted"):
        title = (it.findtext("wantedTitle") or it.findtext("title") or "").strip()
        company = (it.findtext("company") or it.findtext("companyNm") or it.findtext("corpNm") or "").strip()
        region = (it.findtext("region") or it.findtext("workRegion") or "").strip()
        end_date = (it.findtext("endDate") or it.findtext("receiptCloseDt") or "").strip()
        wanted_auth_no = (it.findtext("wantedAuthNo") or it.findtext("wantedno") or "").strip()
        info_url = (it.findtext("wantedInfoUrl") or "").strip()

        blob = f"{title} {company}".lower()
        if not any(k in blob for k in [k.lower() for k in keywords]):
            continue

        link = info_url
        if not link and wanted_auth_no:
            link = "https://www.work.go.kr/empInfo/empInfoSrch/list/dtlEmpSrch.do?wantedAuthNo=" + quote(wanted_auth_no)

        out.append(
            {
                "title": title,
                "company": company,
                "region": region,
                "end_date": end_date,
                "link": link,
                "wanted_auth_no": wanted_auth_no,
                "source": "worknet",
            }
        )
        if len(out) >= max(1, min(int(limit or 5), 5)):
            break

    if not out:
        return json.dumps(
            {"status": "empty", "msg": ("í˜„ì¬ ì§„í–‰ ì¤‘ì¸ í•´ìš´/ë¬¼ë¥˜ ì±„ìš© ê³µê³ ê°€ ì—†ìŠµë‹ˆë‹¤." if lang != "en" else "No maritime/logistics jobs found."), "jobs": []},
            ensure_ascii=False,
        )

    return json.dumps({"status": "success", "query": q, "jobs": out}, ensure_ascii=False)

_YOUTH_CENTER_JOB_CACHE: Dict[str, Tuple[float, Dict[str, Any]]] = {}
_YOUTH_CENTER_JOB_CACHE_TTL_SECONDS = int(os.environ.get("ARA_YOUTH_CENTER_CACHE_TTL_SECONDS", "86400"))

def _yc_cache_get(key: str) -> Optional[Dict[str, Any]]:
    item = _YOUTH_CENTER_JOB_CACHE.get(key)
    if not item:
        return None
    ts, val = item
    if time.time() - ts > float(_YOUTH_CENTER_JOB_CACHE_TTL_SECONDS or 0):
        _YOUTH_CENTER_JOB_CACHE.pop(key, None)
        return None
    return val

def _yc_cache_set(key: str, value: Dict[str, Any]) -> None:
    _YOUTH_CENTER_JOB_CACHE[key] = (time.time(), value)

async def get_youth_center_jobs(query: str, limit: int = 5, lang: str = "ko") -> str:
    """
    ì˜¨í†µì²­ë…„/Work24(Youth Center) API: searchJob.do
    - ì‘ë‹µ(XML) â†’ dict(JSON) ë³€í™˜ í›„, í•„ìš”í•œ í•„ë“œë§Œ ì¶”ì¶œ
    - ìºì‹œ: 24h(in-memory)
    """
    import requests
    import xmltodict

    lang = (lang or "ko").strip().lower()
    if lang not in {"ko", "en"}:
        lang = "ko"

    api_key = (os.environ.get("YOUTH_CENTER_API_KEY") or os.environ.get("WORK24_OPENAPI_KEY") or "").strip()
    if not api_key:
        api_key = "ba0aad9d-c862-410c-90ac-130b556e370e"
    if not api_key:
        return json.dumps({"status": "error", "msg": ("ì •ë³´ë¥¼ í™•ì¸ ì¤‘ì…ë‹ˆë‹¤" if lang != "en" else "Data is being verified.")}, ensure_ascii=False)

    q = (query or "").strip()
    if not q:
        q = "í•´ìš´ ë¬¼ë¥˜"

    limit_n = max(1, min(int(limit or 5), 5))
    endpoint = "https://www.work24.go.kr/openapi/openapi/common/searchJob.do"
    timeout_s = float(os.environ.get("ARA_YOUTH_CENTER_TIMEOUT_SECONDS", "3.5"))
    num_rows = str(max(10, min(limit_n * 6, 60)))

    cache_key = f"YOUTH24:{q}:{limit_n}"
    cached = _yc_cache_get(cache_key)
    if cached is not None:
        return json.dumps(cached, ensure_ascii=False)

    def _fetch_xml(params: Dict[str, Any]) -> str:
        r = requests.get(endpoint, params=params, headers=HEADERS, timeout=timeout_s, verify=HTTPX_VERIFY)
        r.raise_for_status()
        return r.text or ""

    params_candidates = [
        {"apiKey": api_key, "keyword": q, "pageNo": "1", "numOfRows": num_rows},
        {"serviceKey": api_key, "keyword": q, "pageNo": "1", "numOfRows": num_rows},
        {"authKey": api_key, "keyword": q, "pageNo": "1", "numOfRows": num_rows},
    ]

    xml_text = ""
    for p in params_candidates:
        try:
            xml_text = await asyncio.to_thread(_fetch_xml, p)
            if xml_text:
                break
        except Exception:
            continue

    if not xml_text:
        payload = {"status": "error", "msg": ("í˜„ì¬ ì±„ìš© ì •ë³´ë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤." if lang != "en" else "Unable to fetch jobs right now.")}
        _yc_cache_set(cache_key, payload)
        return json.dumps(payload, ensure_ascii=False)

    try:
        parsed = xmltodict.parse(xml_text)
    except Exception:
        payload = {"status": "error", "msg": ("í˜„ì¬ ì±„ìš© ì •ë³´ë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤." if lang != "en" else "Unable to fetch jobs right now.")}
        _yc_cache_set(cache_key, payload)
        return json.dumps(payload, ensure_ascii=False)

    def _iter_dicts(node: Any) -> List[Dict[str, Any]]:
        out: List[Dict[str, Any]] = []
        if isinstance(node, dict):
            out.append(node)
            for v in node.values():
                out.extend(_iter_dicts(v))
        elif isinstance(node, list):
            for it in node:
                out.extend(_iter_dicts(it))
        return out

    def _extract_items(node: Any) -> List[Dict[str, Any]]:
        if isinstance(node, dict):
            for k in ["items", "itemList", "jobList", "jobs", "list"]:
                v = node.get(k)
                if v is None:
                    continue
                found = _extract_items(v)
                if found:
                    return found
            if "item" in node:
                v = node.get("item")
                if isinstance(v, list):
                    return [x for x in v if isinstance(x, dict)]
                if isinstance(v, dict):
                    return [v]
            return []
        if isinstance(node, list):
            out: List[Dict[str, Any]] = []
            for it in node:
                out.extend(_extract_items(it))
            return out
        return []

    items = _extract_items(parsed) or []
    if not items:
        payload = {"status": "empty", "msg": ("í˜„ì¬ ì§„í–‰ ì¤‘ì¸ ì±„ìš© ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤." if lang != "en" else "No jobs found."), "query": q, "jobs": []}
        _yc_cache_set(cache_key, payload)
        return json.dumps(payload, ensure_ascii=False)

    def _pick(it: Dict[str, Any], keys: List[str]) -> str:
        for k in keys:
            v = it.get(k)
            if v is None:
                continue
            if isinstance(v, (str, int, float)):
                s = str(v).strip()
                if s:
                    return s
        return ""

    out: List[Dict[str, Any]] = []
    for it in items:
        if not isinstance(it, dict):
            continue
        title = _pick(it, ["programNm", "programName", "title", "jobTitle", "wantedTitle", "recrtTitle", "sj"])
        summary = _pick(it, ["benefit", "benefitCn", "summary", "desc", "description", "cn", "content"])
        deadline = _pick(it, ["deadline", "ddlnDt", "endDate", "closeDt", "receiptCloseDt", "endYmd", "end_ymd"])
        detail = _pick(it, ["detailUrl", "detailURL", "url", "link", "detailPageUrl", "homepage", "pageUrl"])

        if not title:
            continue

        if detail:
            out.append(
                {
                    "title": title,
                    "summary": summary,
                    "deadline": deadline,
                    "detail_url": detail,
                }
            )
        if len(out) >= limit_n:
            break

    if not out:
        payload = {"status": "empty", "msg": ("í˜„ì¬ ì§„í–‰ ì¤‘ì¸ ì±„ìš© ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤." if lang != "en" else "No jobs found."), "query": q, "jobs": []}
        _yc_cache_set(cache_key, payload)
        return json.dumps(payload, ensure_ascii=False)

    payload = {"status": "success", "source": "youth_center_work24", "query": q, "jobs": out}
    _yc_cache_set(cache_key, payload)
    return json.dumps(payload, ensure_ascii=False)

async def get_youth_jobs(keyword: Optional[str] = None) -> str:
    """
    Stable & Error-Free Employment Data Fetching from Youth Center API.
    - Philosophy: Stability First. Fail gracefully with helpful fallback.
    - API: https://www.youthcenter.go.kr/opi/youthPolicyList.do
    - Always returns valid JSON compatible with KakaoTalk API.
    """
    import xmltodict

    # API Configuration
    api_url = "https://www.youthcenter.go.kr/opi/youthPolicyList.do"
    api_key = "ba0aad9d-c862-410c-90ac-130b556e370e"
    default_thumbnail = "https://images.unsplash.com/photo-1454165804606-c3d57bc86b40?q=80&w=600&auto=format&fit=crop"
    timeout_seconds = 4.0  # Strict 4 seconds (Kakao limit is 5s)

    # Normalize keyword - default to 'ì·¨ì—…' if empty or vague
    q = (keyword or "").strip()
    if not q or len(q) < 2:
        q = "ì·¨ì—…"

    try:
        # Prepare request parameters
        params = {
            "openApiVlak": api_key,
            "display": "5",
            "pageIndex": "1",
            "query": q
        }

        # Make API request with strict timeout
        headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36",
            "Accept": "application/xml,text/xml,*/*"
        }

        async with httpx.AsyncClient(verify=HTTPX_VERIFY, headers=headers, timeout=timeout_seconds) as client:
            response = await client.get(api_url, params=params)
            response.raise_for_status()

            if response.status_code != 200:
                raise RuntimeError(f"HTTP {response.status_code}")

            xml_text = response.text or ""
            if not xml_text.strip():
                raise RuntimeError("Empty response")

            # Check if response is HTML (error page)
            if xml_text.lstrip().lower().startswith("<html"):
                raise RuntimeError("HTML response received instead of XML")

    except (httpx.TimeoutException, httpx.ConnectError, httpx.RequestError) as e:
        # Connection/Timeout errors - return user-friendly message
        return json.dumps({
            "status": "error",
            "msg": "ì§€ê¸ˆ ì •ë¶€ ì„œë²„ë‘ ì—°ê²°ì´ ì¡°ê¸ˆ ì§€ì—°ë˜ê³  ìˆì–´! ì ì‹œ í›„ì— ë‹¤ì‹œ ë¬¼ì–´ë´ì¤„ë˜? ğŸ”§",
            "query": q,
            "policies": []
        }, ensure_ascii=False)

    except Exception as e:
        # Log for debugging but return graceful error
        print(f"[ARA Log] Youth Jobs API Error: {e}")
        return json.dumps({
            "status": "error",
            "msg": "ì§€ê¸ˆ ì •ë¶€ ì„œë²„ë‘ ì—°ê²°ì´ ì¡°ê¸ˆ ì§€ì—°ë˜ê³  ìˆì–´! ì ì‹œ í›„ì— ë‹¤ì‹œ ë¬¼ì–´ë´ì¤„ë˜? ğŸ”§",
            "query": q,
            "policies": []
        }, ensure_ascii=False)

    # Robust XML Parsing
    try:
        parsed = xmltodict.parse(xml_text)
        
        # Navigate to youthPolicyList
        youth_policy_list = None
        if isinstance(parsed, dict):
            # Try different possible structures
            if "youthPolicyList" in parsed:
                youth_policy_list = parsed["youthPolicyList"]
            elif "response" in parsed and isinstance(parsed["response"], dict):
                if "youthPolicyList" in parsed["response"]:
                    youth_policy_list = parsed["response"]["youthPolicyList"]
                elif "body" in parsed["response"] and isinstance(parsed["response"]["body"], dict):
                    if "youthPolicyList" in parsed["response"]["body"]:
                        youth_policy_list = parsed["response"]["body"]["youthPolicyList"]

        if not youth_policy_list:
            # Log raw response for debugging (status 200 but empty data)
            print(f"[ARA Log] Youth Jobs API: Status 200 but no youthPolicyList found. Response preview: {xml_text[:200]}")
            
            # Try fallback search with 'ì²­ë…„'
            if q != "ì²­ë…„":
                return await get_youth_jobs("ì²­ë…„")
            
            return json.dumps({
                "status": "empty",
                "msg": "ì§€ê¸ˆ ì •ë¶€ ì„œë²„ë‘ ì—°ê²°ì´ ì¡°ê¸ˆ ì§€ì—°ë˜ê³  ìˆì–´! ì ì‹œ í›„ì— ë‹¤ì‹œ ë¬¼ì–´ë´ì¤„ë˜? ğŸ”§",
                "query": q,
                "policies": []
            }, ensure_ascii=False)

        # Handle totalCnt check
        total_cnt = 0
        if isinstance(youth_policy_list, dict):
            total_cnt_str = str(youth_policy_list.get("totalCnt", "0") or "0")
            try:
                total_cnt = int(total_cnt_str)
            except (ValueError, TypeError):
                total_cnt = 0
        
        # If totalCnt is 0, try fallback search with 'ì²­ë…„'
        if total_cnt == 0 and q != "ì²­ë…„":
            return await get_youth_jobs("ì²­ë…„")

        # Extract youthPolicy - handle both single dict and list
        youth_policies = []
        if isinstance(youth_policy_list, dict):
            if "youthPolicy" in youth_policy_list:
                policy_data = youth_policy_list["youthPolicy"]
                # Convert single dict to list
                if isinstance(policy_data, dict):
                    youth_policies = [policy_data]
                elif isinstance(policy_data, list):
                    youth_policies = policy_data

        # Normalize items for KakaoTalk UI
        items = []
        for policy in youth_policies:
            if not isinstance(policy, dict):
                continue

            # Extract fields
            policy_name = (
                policy.get("polyBizSjnm") or 
                policy.get("polyBizSjNm") or 
                policy.get("policyName") or 
                policy.get("name") or 
                ""
            ).strip()

            intro = (
                policy.get("polyItcnCn") or 
                policy.get("polyItcnCnNm") or 
                policy.get("intro") or 
                policy.get("summary") or 
                ""
            ).strip()

            biz_id = (
                policy.get("bizId") or 
                policy.get("bizid") or 
                ""
            ).strip()

            # Truncate intro to 40 chars for description
            intro_short = intro[:40] if len(intro) > 40 else intro

            # Build detail URL using bizId
            detail_url = f"https://www.youthcenter.go.kr/youngPlcyUnif/youngPlcyUnifDtl.do?bizId={biz_id}" if biz_id else "https://www.youthcenter.go.kr"

            if policy_name:
                items.append({
                    "policyName": policy_name,
                    "polyItcnCn": intro_short,
                    "bizId": biz_id,
                    "detail_url": detail_url,
                    "thumbnail": default_thumbnail
                })

        if not items:
            # Try fallback search if no items found
            if q != "ì²­ë…„":
                return await get_youth_jobs("ì²­ë…„")
            
            return json.dumps({
                "status": "empty",
                "msg": "ì§€ê¸ˆ ì •ë¶€ ì„œë²„ë‘ ì—°ê²°ì´ ì¡°ê¸ˆ ì§€ì—°ë˜ê³  ìˆì–´! ì ì‹œ í›„ì— ë‹¤ì‹œ ë¬¼ì–´ë´ì¤„ë˜? ğŸ”§",
                "query": q,
                "policies": []
            }, ensure_ascii=False)

        # Return success response
        return json.dumps({
            "status": "success",
            "source": "youth_center_policy",
            "query": q,
            "policies": items
        }, ensure_ascii=False)

    except Exception as e:
        # XML parsing errors
        print(f"[ARA Log] Youth Jobs XML Parsing Error: {e}")
        return json.dumps({
            "status": "error",
            "msg": "ì§€ê¸ˆ ì •ë¶€ ì„œë²„ë‘ ì—°ê²°ì´ ì¡°ê¸ˆ ì§€ì—°ë˜ê³  ìˆì–´! ì ì‹œ í›„ì— ë‹¤ì‹œ ë¬¼ì–´ë´ì¤„ë˜? ğŸ”§",
            "query": q,
            "policies": []
        }, ensure_ascii=False)

async def get_youth_center_info(query: Optional[str] = None, limit: int = 5, lang: str = "ko") -> str:
    import requests
    import xmltodict

    lang = (lang or "ko").strip().lower()
    if lang not in {"ko", "en"}:
        lang = "ko"

    api_key = (os.environ.get("YOUTH_CENTER_API_KEY") or "").strip()
    if not api_key:
        api_key = "ba0aad9d-c862-410c-90ac-130b556e370e"

    q_raw = (query or "").strip()
    q = q_raw
    if any(k in q for k in ["ì„¸ë¬´", "íšŒê³„", "ë²•", "ë…¸ë¬´", "í–‰ì •", "ì¸ì‚¬", "ì´ë¬´", "ë§ˆì¼€íŒ…", "ê²½ì˜", "ì‚¬íšŒ"]):
        q = q_raw

    limit_n = max(5, min(int(limit or 10), 10))
    endpoint_https = "https://www.youthcenter.go.kr/opi/youthPolicyList.do"
    endpoint_http_8080 = "http://www.youthcenter.go.kr:8080/opi/youthPolicyList.do"
    timeout_s = 4.0

    cache_key = f"YOUTH_POLICY:{q}:{limit_n}:{lang}"
    cached = _yc_cache_get(cache_key)
    if cached is not None:
        return json.dumps(cached, ensure_ascii=False)

    def _fetch(params: Dict[str, Any]) -> str:
        headers = {"User-Agent": "Mozilla/5.0", "Accept": "application/xml,text/xml,*/*"}

        last_err: Exception | None = None
        for url in [endpoint_https, endpoint_http_8080]:
            try:
                allow_redirects = False if url == endpoint_https else True
                r = requests.get(url, params=params, headers=headers, timeout=timeout_s, verify=HTTPX_VERIFY, allow_redirects=allow_redirects)
                if (r.status_code in (301, 302, 303, 307, 308)) and url == endpoint_https:
                    raise RuntimeError(f"Redirected: {r.headers.get('location')}")
                if r.status_code != 200:
                    raise RuntimeError(f"HTTP {r.status_code}")
                if not r.encoding:
                    r.encoding = r.apparent_encoding or "utf-8"
                text = r.text or ""
                if text.lstrip().lower().startswith("<html"):
                    raise RuntimeError("HTML response")
                return text
            except Exception as e:
                last_err = e
                continue
        raise last_err or RuntimeError("request failed")

    def _parse_items(xml_text: str) -> List[Dict[str, Any]]:
        parsed = xmltodict.parse(xml_text)

        def _walk(node: Any):
            if isinstance(node, dict):
                yield node
                for v in node.values():
                    yield from _walk(v)
            elif isinstance(node, list):
                for it in node:
                    yield from _walk(it)

        def _as_list(v: Any) -> List[Dict[str, Any]]:
            if isinstance(v, list):
                return [x for x in v if isinstance(x, dict)]
            if isinstance(v, dict):
                return [v]
            return []

        for d in _walk(parsed):
            if "youthPolicyList" in d:
                ypl = d.get("youthPolicyList")
                if isinstance(ypl, dict) and ("youthPolicy" in ypl):
                    return _as_list(ypl.get("youthPolicy"))
                return _as_list(ypl)

        for d in _walk(parsed):
            if "youthPolicy" in d:
                return _as_list(d.get("youthPolicy"))

        return []

    def _pick(it: Dict[str, Any], keys: List[str]) -> str:
        for k in keys:
            v = it.get(k)
            if v is None:
                continue
            if isinstance(v, (str, int, float)):
                s = str(v).strip()
                if s:
                    return s
        return ""

    def _normalize(items: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        out: List[Dict[str, Any]] = []
        seen: set[str] = set()
        for it in items:
            if not isinstance(it, dict):
                continue
            name = _pick(it, ["policyName", "polyBizSjnm", "polyBizSjNm", "polyBizSjnmNm", "title", "name"])
            intro = _pick(it, ["polyItcnCn", "polyItcnCnNm", "intro", "summary", "cn", "content"])
            prd = _pick(it, ["bizPrdCn", "bizPrdCnNm", "bizPrd", "period"])
            url = _pick(it, ["detailUrl", "detailURL", "url", "link", "pageUrl", "homepage"])

            if not url:
                if q:
                    url = f"https://www.youthcenter.go.kr/?srchWord={quote_plus(q)}"
                else:
                    url = "https://www.youthcenter.go.kr"

            key = (name + "|" + prd + "|" + url).strip()
            if not name or key in seen:
                continue
            seen.add(key)
            out.append({"policyName": name, "polyItcnCn": intro, "bizPrdCn": prd, "detail_url": url})
            if len(out) >= limit_n:
                break
        return out

    def _request_once(query_text: str | None) -> List[Dict[str, Any]]:
        params = {"authKey": api_key, "display": "10", "pageIndex": "1"}
        if query_text:
            params["query"] = query_text
        xml_text = _fetch(params)
        items = _parse_items(xml_text)
        return _normalize(items)

    try:
        items = []
        if q:
            try:
                items = await asyncio.to_thread(_request_once, q)
            except Exception:
                items = []
        if len(items) < 5:
            try:
                more = await asyncio.to_thread(_request_once, None)
                merged = { (it.get("policyName","") + "|" + it.get("detail_url","")).strip(): it for it in items if isinstance(it, dict) }
                for it in more:
                    k2 = (it.get("policyName","") + "|" + it.get("detail_url","")).strip()
                    if k2 and k2 not in merged:
                        merged[k2] = it
                    if len(merged) >= limit_n:
                        break
                items = list(merged.values())[:limit_n]
            except Exception:
                pass

        if not items:
            payload = {"status": "empty", "msg": ("ì§€ê¸ˆì€ ì •ì±… ì •ë³´ë¥¼ ì°¾ì§€ ëª»í–ˆì–´. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì¤˜!" if lang != "en" else "No policies found."), "query": q, "policies": []}
            _yc_cache_set(cache_key, payload)
            return json.dumps(payload, ensure_ascii=False)

        payload = {"status": "success", "source": "youthcenter_policy", "query": q, "policies": items}
        _yc_cache_set(cache_key, payload)
        return json.dumps(payload, ensure_ascii=False)
    except Exception:
        payload = {"status": "error", "msg": ("ì§€ê¸ˆì€ ì •ì±… ì •ë³´ë¥¼ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆì–´. ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì¤˜!" if lang != "en" else "Unable to fetch policies right now.")}
        _yc_cache_set(cache_key, payload)
        return json.dumps(payload, ensure_ascii=False)

# =========================
# 4) ì…”í‹€/ìº í¼ìŠ¤ë§µ (ì´ë¯¸ì§€ ê¸°ë°˜ ê¸°ëŠ¥ ì¶”ê°€)
# =========================

def get_current_season(today: Optional[date] = None) -> str:
    """
    SeasonDetector (ìš”ì²­ ë°˜ì˜)
    - Winter Vacation: ~ 2026-02-28 (inclusive)
    - Spring Semester(1st): 2026-03-02 ~ 2026-06-21 (inclusive)
    """
    d = today or date.today()
    if d <= date(2026, 2, 28):
        return "VACATION"
    if date(2026, 3, 2) <= d <= date(2026, 6, 21):
        return "SEMESTER"
    # ë²”ìœ„ ì™¸ì—ëŠ” ê°€ì¥ ë³´ìˆ˜ì ìœ¼ë¡œ í•™ê¸°ì¤‘ìœ¼ë¡œ ê°„ì£¼(ìš”ì²­: 3/2 ì´í›„ ìë™ ì „í™˜)
    if d >= date(2026, 3, 2):
        return "SEMESTER"
    return "VACATION"

def _hhmm_to_minutes(hhmm: str) -> Optional[int]:
    if not hhmm:
        return None
    s = re.sub(r"\s+", "", str(hhmm))
    m = re.match(r"^(\d{1,2}):(\d{2})$", s)
    if not m:
        m = re.match(r"^(\d{3,4})$", re.sub(r"\D+", "", s))
        if not m:
            return None
        digits = m.group(1).zfill(4)
        h, mi = int(digits[:2]), int(digits[2:])
    else:
        h, mi = int(m.group(1)), int(m.group(2))
    if not (0 <= h <= 23 and 0 <= mi <= 59):
        return None
    return h * 60 + mi

def _minutes_to_hhmm(m: int) -> str:
    h = m // 60
    mi = m % 60
    return f"{h:02d}:{mi:02d}"

_SHUTTLE_SEMESTER: Dict[str, List[str]] = {
    "1-1": ["08:15", "09:00", "18:10"],
    "2-1": ["08:00", "08:55", "11:00", "13:00", "16:10", "18:10"],
}

def _shuttle_3_1_semester_times() -> List[str]:
    # 08:00 ~ 21:30, 20ë¶„ ê°„ê²©
    start = 8 * 60
    end = 21 * 60 + 30
    return [_minutes_to_hhmm(m) for m in range(start, end + 1, 20)]

_SHUTTLE_VACATION: Dict[str, Optional[List[str]]] = {
    "1-1": None,  # ë°©í•™ì¤‘ ë¯¸ìš´í–‰
    "2-1": None,  # ë°©í•™ì¤‘ ë¯¸ìš´í–‰
    "3-1": [
        "08:00", "08:30", "09:00", "09:30", "10:00",
        "11:00", "11:30", "12:00", "12:30",
        "14:00", "14:30", "15:00", "15:30",
        "16:00", "16:30", "17:00",
        "18:10", "18:30", "19:00", "20:00", "21:00",
    ],
}

_SHUTTLE_NOTICE = "ì£¼ë§ ë° ë²•ì • ê³µíœ´ì¼ ìš´í–‰ ì—†ìŒ"

# ì´ë¯¸ì§€(ì‹œê°„í‘œ) í•˜ë‹¨ í…ìŠ¤íŠ¸ ê¸°ë°˜ ë…¸ì„  ì•ˆë‚´
_SHUTTLE_ROUTE_BASE = (
    "í•™ë‚´ ì¶œë°œì (í•´ì‚¬ëŒ€í•™ê´€ ì•) â†’ ê³µê³¼ëŒ€í•™ 1í˜¸ê´€ ì• â†’ ìŠ¹ì„ ìƒí™œê´€ ì…êµ¬ â†’ ë¦´ë™ìŠ¤ê²Œì´íŠ¸ â†’ íƒœì¢…ëŒ€ ê³¼ì¼ê°€ê²Œ ì• â†’ ì‹ í¥í•˜ë¦¬ìƒê°€ â†’ "
    "ë¦´ë™ìŠ¤ê²Œì´íŠ¸ â†’ ìŠ¹ì„ ìƒí™œê´€ ì…êµ¬ â†’ í•™ë‚´ì§„ì…ì‹œ ì•µì»¤íƒ‘ ì• ì¢ŒíšŒì „(ì‹¤ìŠµì„  ë¶€ë‘ ë°©ë©´) â†’ ê³µëŒ€ 1í˜¸ê´€ í›„ë¬¸ â†’ ì–´ìš¸ë¦¼ê´€ â†’ í•™ë‚´ ì¢…ì (í•´ì‚¬ëŒ€í•™ê´€ ì•)"
)
_SHUTTLE_ROUTE_MARKET = (
    "í•™êµ ì¶œë°œ 12:40, 14:00, 18:10, 20:30 / í•™ë‚´ ì¢…ì (í•´ì‚¬ëŒ€í•™ê´€ ì•) â†’ ê³µê³¼ëŒ€í•™ 1í˜¸ê´€ ì• â†’ ìŠ¹ì„ ìƒí™œê´€ ì…êµ¬ â†’ ë¦´ë™ìŠ¤ê²Œì´íŠ¸ â†’ "
    "ë¡¯ë°ë¦¬ì•„ì˜ë„ì  ë§ì€í¸ ë²„ìŠ¤ ì •ë¥˜ì¥ â†’ ë™ì‚¼ì‹œì¥ â†’ ë™ì‚¼ì‹œë¯¼ê³µì›ì…êµ¬(ë§¤ë¬¼ë…€5ë²ˆ ì •ë¥˜ì¥) â†’ íƒœì¢…ëŒ€ ê³¼ì¼ê°€ê²Œ ì• â†’ ì‹ í¥í•˜ë¦¬ìƒê°€ â†’ "
    "ë¦´ë™ìŠ¤ê²Œì´íŠ¸ â†’ ìŠ¹ì„ ìƒí™œê´€ ì…êµ¬ â†’ í•™ë‚´ì§„ì…ì‹œ ì•µì»¤íƒ‘ ì•ì—ì„œ ì¢ŒíšŒì „(ì‹¤ìŠµì„  ë¶€ë‘ ë°©ë©´) â†’ ê³µëŒ€ 1í˜¸ê´€ í›„ë¬¸ â†’ ì–´ìš¸ë¦¼ê´€ â†’ í•™ë‚´ ì¢…ì (í•´ì‚¬ëŒ€í•™ê´€ ì•)"
)

async def get_shuttle_next_buses(limit: int = 3, now_hhmm: Optional[str] = None, date_yyyymmdd: Optional[str] = None, lang: str = "ko"):
    """ì…”í‹€ ë‹¤ìŒ NíšŒ ì¶œë°œ(ì‹œì¦Œ ìë™ ì „í™˜ + ì‹¤ì‹œê°„ í•„í„°)"""
    # ê¸°ì¤€ ì‹œê°(KST)
    now_dt = datetime.now(_KST)
    if date_yyyymmdd:
        digits = re.sub(r"\D+", "", str(date_yyyymmdd))
        if len(digits) == 8:
            try:
                now_dt = datetime(int(digits[0:4]), int(digits[4:6]), int(digits[6:8]), now_dt.hour, now_dt.minute)
            except Exception:
                pass
    if now_hhmm:
        mm = _hhmm_to_minutes(now_hhmm)
        if mm is not None:
            now_dt = now_dt.replace(hour=mm // 60, minute=mm % 60, second=0, microsecond=0)

    lang = (lang or "ko").strip().lower()
    season = get_current_season(now_dt.date())
    is_weekend = now_dt.weekday() >= 5
    # ë²•ì • ê³µíœ´ì¼ íŒë‹¨ì€ calendar_2026.jsonë§Œ ì‚¬ìš©(ê³„ì‚° ê¸ˆì§€)
    ymd = now_dt.strftime("%Y%m%d")
    is_holiday = is_holiday_2026(ymd)
    if is_weekend or (is_holiday is True):
        return json.dumps(
            {
                "status": "no_service",
                "season": season,
                "msg": _SHUTTLE_NOTICE,
                "next": [],
                "route_base": _SHUTTLE_ROUTE_BASE,
                "route_market": _SHUTTLE_ROUTE_MARKET,
            },
            ensure_ascii=False,
        )

    cur_min = now_dt.hour * 60 + now_dt.minute

    departures: List[Tuple[int, str]] = []
    inactive: List[str] = []

    season_label = None
    if season == "VACATION":
        season_label = "Winter Vacation Schedule (No. 3-1)" if lang == "en" else "[â„ï¸ ë°©í•™ì¤‘] 3-1 í•˜ë¦¬ì „ìš©"
        schedule = _SHUTTLE_VACATION
        if schedule.get("1-1") is None:
            inactive.append("1-1")
        if schedule.get("2-1") is None:
            inactive.append("2-1")
        times_3 = schedule.get("3-1") or []
        for t in times_3:
            m = _hhmm_to_minutes(t)
            if m is not None:
                departures.append((m, "3-1 (Hari)" if lang == "en" else "3-1 í•˜ë¦¬ì „ìš©"))
    else:
        season_label = "Semester Schedule" if lang == "en" else "[ğŸŒ¸ í•™ê¸°ì¤‘] ì…”í‹€"
        schedule = dict(_SHUTTLE_SEMESTER)
        # 3-1 í•™ê¸°ì¤‘ 20ë¶„ ê°„ê²©
        schedule["3-1"] = _shuttle_3_1_semester_times()
        for bus_id, times in schedule.items():
            for t in times:
                m = _hhmm_to_minutes(t)
                if m is not None:
                    label = bus_id if bus_id in {"1-1", "2-1"} else ("3-1 (Hari)" if lang == "en" else "3-1 í•˜ë¦¬ì „ìš©")
                    departures.append((m, label))

    departures = sorted([d for d in departures if d[0] >= cur_min], key=lambda x: x[0])
    picked = departures[: max(0, int(limit))]

    if not picked:
        return json.dumps(
            {
                "status": "ended",
                "season": season,
                "season_label": season_label,
                "msg": "ì˜¤ëŠ˜ ìš´í–‰ì´ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.",
                "next": [],
                "inactive": inactive,
                "route_base": _SHUTTLE_ROUTE_BASE,
                "route_market": _SHUTTLE_ROUTE_MARKET,
                "notice": _SHUTTLE_NOTICE,
            },
            ensure_ascii=False,
        )

    return json.dumps(
        {
            "status": "success",
            "season": season,
            "season_label": season_label,
            "now": now_dt.strftime("%Y-%m-%d %H:%M"),
            "inactive": inactive,
            "next": [{"bus": bus, "time": _minutes_to_hhmm(m)} for m, bus in picked],
            "route_base": _SHUTTLE_ROUTE_BASE,
            "route_market": _SHUTTLE_ROUTE_MARKET,
            "notice": _SHUTTLE_NOTICE,
        },
        ensure_ascii=False,
    )

async def get_shuttle_schedule(current_time: Optional[str] = None, date_yyyymmdd: Optional[str] = None, lang: str = "ko"):
    """
    ë‹¤ìŒ ì…”í‹€ 1íšŒë§Œ ë°˜í™˜(ìš”êµ¬ì‚¬í•­)
    - current_time: 'HH:MM' (ë¯¸ì…ë ¥ ì‹œ KST í˜„ì¬ì‹œê° ì‚¬ìš©)
    - ë°©í•™(2026-01-20)ì€ VACATIONìœ¼ë¡œ 3-1(í•˜ë¦¬)ë§Œ ê¸°ë³¸ í™œì„±
    - Output: "Next shuttle is at [Time] (Type: Loop/Commute)"
    """
    lang = (lang or "ko").strip().lower()
    if lang not in {"ko", "en"}:
        lang = "ko"

    now_dt = datetime.now(_KST)
    if date_yyyymmdd:
        digits = re.sub(r"\D+", "", str(date_yyyymmdd))
        if len(digits) == 8:
            try:
                now_dt = datetime(int(digits[0:4]), int(digits[4:6]), int(digits[6:8]), now_dt.hour, now_dt.minute, tzinfo=_KST)
            except Exception:
                pass

    if current_time:
        mm = _hhmm_to_minutes(current_time)
        if mm is not None:
            now_dt = now_dt.replace(hour=mm // 60, minute=mm % 60, second=0, microsecond=0)
    current_time_str = now_dt.strftime("%H:%M")

    season = get_current_season(now_dt.date())
    cur_min = now_dt.hour * 60 + now_dt.minute

    # ì£¼ë§/ê³µíœ´ì¼ ìš´í–‰ ì—†ìŒ(ê¸°ì¡´ ì •ì±…)
    ymd = now_dt.strftime("%Y%m%d")
    is_weekend = now_dt.weekday() >= 5
    is_holiday = is_holiday_2026(ymd)
    if is_weekend or (is_holiday is True):
        msg = ("No service on weekends/holidays." if lang == "en" else "ê¸ˆì¼ ì…”í‹€ ìš´í–‰ì´ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
        return json.dumps({"status": "ended", "season": season, "msg": msg}, ensure_ascii=False)

    # ë‹¤ìŒ ì¶œë°œ í›„ë³´ ìƒì„±
    candidates: List[Tuple[int, str, str]] = []  # (minutes, bus, type)

    if season == "VACATION":
        # ë°©í•™: 3-1 í•˜ë¦¬ì „ìš©ë§Œ
        for t in (_SHUTTLE_VACATION.get("3-1") or []):
            m = _hhmm_to_minutes(t)
            if m is None:
                continue
            candidates.append((m, "3-1 (Hari)", "Loop"))
    else:
        # í•™ê¸°: 1-1/2-1(í†µí•™) + 3-1(ìˆœí™˜)
        for bus_id, times in _SHUTTLE_SEMESTER.items():
            for t in (times or []):
                m = _hhmm_to_minutes(t)
                if m is None:
                    continue
                candidates.append((m, bus_id, "Commute"))
        for t in _shuttle_3_1_semester_times():
            m = _hhmm_to_minutes(t)
            if m is None:
                continue
            candidates.append((m, "3-1", "Loop"))

    candidates = sorted([c for c in candidates if c[0] >= cur_min], key=lambda x: x[0])
    if not candidates:
        msg = ("Service has ended for today." if lang == "en" else "ê¸ˆì¼ ì…”í‹€ ìš´í–‰ì´ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
        return json.dumps({"status": "ended", "season": season, "msg": msg}, ensure_ascii=False)

    next_m, bus, typ = candidates[0]
    next_time = _minutes_to_hhmm(next_m)

    if lang == "en":
        msg = f"Next shuttle is at {next_time} (Type: {typ})"
    else:
        # ìš”êµ¬ í¬ë§· ì¤€ìˆ˜
        if "Hari" in bus or "í•˜ë¦¬" in bus:
            dest = "í•˜ë¦¬í–‰"
        else:
            dest = "í†µí•™" if typ == "Commute" else "ìˆœí™˜"
        msg = f"í˜„ì¬ ì‹œê°({current_time_str}) ê¸°ì¤€, ë‹¤ìŒ ì…”í‹€ì€ [{next_time}]ì— ìˆìŠµë‹ˆë‹¤. ({dest})"
    return json.dumps({"status": "success", "season": season, "next_time": next_time, "bus": bus, "type": typ, "msg": msg}, ensure_ascii=False)

"""
NOTE: ìº í¼ìŠ¤ ì •ì  ì§€ë„/ì´ë¯¸ì§€ ê¸°ëŠ¥ì€ ìš”êµ¬ì‚¬í•­ì— ë”°ë¼ ì œê±°ë˜ì—ˆìŠµë‹ˆë‹¤.
- í•™êµ ì§€ë„ëŠ” `main.py`ì—ì„œ KMOU í™ˆí˜ì´ì§€(webLink) ê¸°ëŠ¥ìœ¼ë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤.
"""

# =========================
# Tool Specification (CRITICAL)
# =========================

TOOLS_SPEC = [
    {
        "type": "function",
        "function": {
            "name": "get_bus_arrival",
            "description": "ğŸšŒ 190ë²ˆ ë²„ìŠ¤(ë‚¨í¬/ì‹œë‚´í–‰): ì •ë¥˜ì¥ID 03053 ê¸°ì¤€ ë‹¤ìŒ/ë‹¤ë‹¤ìŒ ë„ì°© ì •ë³´ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤(ë°˜í™˜: JSON ë¬¸ìì—´).",
            "parameters": {
                "type": "object",
                "properties": {
                    "bus_number": {"type": "string", "description": "ì˜ˆ: 190 (ë¯¸ì…ë ¥ ì‹œ 190 ê¸°ë³¸ê°’)"},
                    "lang": {"type": "string", "description": "ko ë˜ëŠ” en(ì„ íƒ)"},
                },
            },
        },
    },
    {
        "type": "function",
        "function": {
            "name": "get_bus_190_tracker_busbusinfo",
            "description": "ğŸšŒ 190ë²ˆ ë²„ìŠ¤(í•œêµ­í•´ì–‘ëŒ€ ê¸°ì â†’ë‚¨ë¶€ë¯¼ë™): ì‹¤ì‹œê°„ ìœ„ì¹˜(ì°¨ëŸ‰ëª©ë¡)ì™€ ê¸°ì (04001) ì¶œë°œ ì˜ˆì •(min1) ì •ë³´ë¥¼ í†µí•©í•´ ë°˜í™˜í•©ë‹ˆë‹¤(ë°˜í™˜: JSON ë¬¸ìì—´).",
            "parameters": {
                "type": "object",
                "properties": {
                    "line_id": {"type": "string", "description": "ë…¸ì„  ID (ê¸°ë³¸ 5200190000)"},
                    "kmou_stop_id": {"type": "string", "description": "ê¸°ì  ì •ë¥˜ì¥ ID (ê¸°ë³¸ 04001)"},
                },
            },
        },
    },
    {
        "type": "function",
        "function": {
            "name": "get_kmou_weather",
            "description": "ğŸŒ¤ï¸ Weather: 'ì˜ë„ ë‚ ì”¨' í˜•íƒœë¡œ ì˜ë„êµ¬ ì‹¤ì‹œê°„ ê¸°ìƒ ì‹¤í™©ì„ ì¡°íšŒí•©ë‹ˆë‹¤.",
            "parameters": {"type": "object", "properties": {"lang": {"type": "string", "description": "ko ë˜ëŠ” en(ì„ íƒ)"}}},
        },
    },
    {
        "type": "function",
        "function": {
            "name": "get_weather_info",
            "description": "ğŸŒ¤ï¸ ì˜¤ëŠ˜ì˜ ì˜ë„ ë‚ ì”¨: í’ì†/ì²´ê°ì˜¨ë„ í¬í•¨ ìš”ì•½ì„ ë°˜í™˜í•©ë‹ˆë‹¤(ë°˜í™˜: JSON ë¬¸ìì—´).",
            "parameters": {"type": "object", "properties": {"lang": {"type": "string", "description": "ko ë˜ëŠ” en(ì„ íƒ)"}}},
        },
    },
    {
        "type": "function",
        "function": {
            "name": "get_cheap_eats",
            "description": "ğŸš ì°©í•œê°€ê²© ì‹ë‹¹(êµ¬í˜•): ì˜ë„êµ¬ ì°©í•œê°€ê²©ì—…ì†Œ ì •ë³´ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤.",
            "parameters": {"type": "object", "properties": {"food_type": {"type": "string"}}},
        },
    },
    {
        "type": "function",
        "function": {
            "name": "search_restaurants",
            "description": "ğŸš Restaurants: ìŒì‹ ì¢…ë¥˜(ì˜ˆ: í•œì‹/ì¤‘ì‹/ì¹´í˜/ì»¤í”¼ ë“±)ë¡œ ì˜ë„/í•´ì–‘ëŒ€ ì¸ê·¼ ë§›ì§‘ì„ ë™ì ìœ¼ë¡œ ê²€ìƒ‰í•©ë‹ˆë‹¤(places.csv ë˜ëŠ” ì§€ë„ API).",
            "parameters": {
                "type": "object",
                "properties": {
                    "query": {"type": "string", "description": "ì˜ˆ: í•œì‹, ì¤‘ì‹, ì¹´í˜, ì»¤í”¼, êµ­ë°¥ ë“±"},
                    "limit": {"type": "integer", "description": "ìµœëŒ€ ê²°ê³¼ ìˆ˜(ê¸°ë³¸ 5)"},
                },
                "required": ["query"],
            },
        },
    },
    {
        "type": "function",
        "function": {
            "name": "get_shuttle_next_buses",
            "description": "ğŸš Shuttle: í˜„ì¬ ì‹œê° ê¸°ì¤€ ë‹¤ìŒ NíšŒ ì…”í‹€ ì¶œë°œ ì •ë³´ë¥¼ ì œê³µí•©ë‹ˆë‹¤(ë°©í•™/í•™ê¸° ìë™ ì „í™˜).",
            "parameters": {
                "type": "object",
                "properties": {
                    "limit": {"type": "integer", "description": "ê°€ì ¸ì˜¬ ì¶œë°œ íšŸìˆ˜(ê¸°ë³¸ 3)"},
                    "now_hhmm": {"type": "string", "description": "í…ŒìŠ¤íŠ¸ìš© HH:MM(ì„ íƒ)"},
                    "date_yyyymmdd": {"type": "string", "description": "í…ŒìŠ¤íŠ¸ìš© YYYYMMDD(ì„ íƒ)"},
                    "lang": {"type": "string", "description": "ko ë˜ëŠ” en(ì„ íƒ)"},
                },
            },
        },
    },
    {
        "type": "function",
        "function": {
            "name": "get_shuttle_schedule",
            "description": "ğŸš Shuttle(Next only): í˜„ì¬ ì‹œê° ê¸°ì¤€ ë‹¤ìŒ 1íšŒ ì¶œë°œë§Œ ë°˜í™˜í•©ë‹ˆë‹¤(ë°©í•™/í•™ê¸° ìë™ ì „í™˜).",
            "parameters": {
                "type": "object",
                "properties": {
                    "current_time": {"type": "string", "description": "HH:MM (ì„ íƒ)"},
                    "date_yyyymmdd": {"type": "string", "description": "YYYYMMDD (ì„ íƒ)"},
                    "lang": {"type": "string", "description": "ko ë˜ëŠ” en(ì„ íƒ)"},
                },
            },
        },
    },
    {
        "type": "function",
        "function": {
            "name": "get_calendar_day_2026",
            "description": "ğŸ“… 2026 ìº˜ë¦°ë”(ì§„ì‹¤ ì†ŒìŠ¤): calendar_2026.jsonì— ëª…ì‹œëœ ë‚ ì§œë§Œ í™•ì¸í•©ë‹ˆë‹¤. ì—†ìœ¼ë©´ 'ì—…ë°ì´íŠ¸ ì¤‘'ìœ¼ë¡œë§Œ ì‘ë‹µí•©ë‹ˆë‹¤(ê³„ì‚°/ì¶”ì¸¡ ê¸ˆì§€).",
            "parameters": {
                "type": "object",
                "properties": {"date_yyyymmdd": {"type": "string", "description": "YYYYMMDD (ì˜ˆ: 20260120)"}},
                "required": ["date_yyyymmdd"],
            },
        },
    },
    {
        "type": "function",
        "function": {
            "name": "get_academic_schedule",
            "description": "ğŸ“š 2026 í•™ì‚¬ì¼ì •(D-Day): í•˜ë“œì½”ë”©ëœ 2026 í•™ì‚¬ ì´ë²¤íŠ¸ ë‚ ì§œë¡œ D-Dayë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤(ì›¹ í¬ë¡¤ë§ ê¸ˆì§€).",
            "parameters": {
                "type": "object",
                "properties": {
                    "query": {"type": "string", "description": "ì´ë²¤íŠ¸ëª… ë¶€ë¶„ê²€ìƒ‰(ì˜ˆ: ê°œê°•, ìˆ˜ê°•ì‹ ì²­, ê¸°ë§ê³ ì‚¬) (ì„ íƒ)"},
                    "today_yyyy_mm_dd": {"type": "string", "description": "ê¸°ì¤€ì¼(YYYY-MM-DD) í…ŒìŠ¤íŠ¸ìš© (ì„ íƒ)"},
                    "lang": {"type": "string", "description": "ko ë˜ëŠ” en(ì„ íƒ)"},
                },
            },
        },
    },
    {
        "type": "function",
        "function": {
            "name": "get_astronomy_data",
            "description": "ğŸŒ… ì¼ì¶œ/ì¼ëª°(ì§„ì‹¤ ì†ŒìŠ¤): KASI ì¼ì¶œ/ì¼ëª° APIë¡œ ë¶€ì‚° ì§€ì—­ì˜ sunrise/sunsetì„ ì¡°íšŒí•©ë‹ˆë‹¤. ì‹¤íŒ¨ ì‹œ Update Pending.",
            "parameters": {
                "type": "object",
                "properties": {"target_date": {"type": "string", "description": "YYYYMMDD (ì˜ˆ: 20260120)"}},
                "required": ["target_date"],
            },
        },
    },
    {
        "type": "function",
        "function": {
            "name": "get_campus_contacts",
            "description": "ğŸ“ ìº í¼ìŠ¤ ì—°ë½ì²˜(ì˜¤í”„ë¼ì¸): ë‚´ì¥ JSON(ì§„ì‹¤ ì†ŒìŠ¤)ì—ì„œ í•™êµ ì—°ë½ì²˜ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤.",
            "parameters": {
                "type": "object",
                "properties": {
                    "category": {"type": "string", "description": "ì˜ˆ: Emergency, Academic_Affairs ë“±(ì„ íƒ)"},
                    "office": {"type": "string", "description": "ì˜ˆ: Integrated_Security_Office ë“±(ì„ íƒ)"},
                    "lang": {"type": "string", "description": "ko ë˜ëŠ” en(ì„ íƒ)"},
                },
            },
        },
    },
    {
        "type": "function",
        "function": {
            "name": "get_youth_center_info",
            "description": "ğŸ’¼ ì·¨ì—…(ì˜¨í†µì²­ë…„): youthPolicyList(XML) â†’ JSONìœ¼ë¡œ ë³€í™˜í•´ ì²­ë…„ì •ì±… ëª©ë¡ì„ ë°˜í™˜í•©ë‹ˆë‹¤(ë°˜í™˜: JSON ë¬¸ìì—´).",
            "parameters": {
                "type": "object",
                "properties": {
                    "query": {"type": "string", "description": "ê²€ìƒ‰ í‚¤ì›Œë“œ(ì˜ˆ: í•´ìš´ ë¬¼ë¥˜, ì„¸ë¬´ íšŒê³„, ì²­ë…„ì •ì±…)"},
                    "limit": {"type": "integer", "description": "ìµœëŒ€ ê²°ê³¼ ìˆ˜(ê¸°ë³¸ 5, ìµœëŒ€ 5)"},
                    "lang": {"type": "string", "description": "ko ë˜ëŠ” en(ì„ íƒ)"},
                },
            },
        },
    },
]