from dotenv import load_dotenv
load_dotenv()  # .env íŒŒì¼ì— ì €ì¥ëœ í‚¤ë¥¼ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤.
import os
from pathlib import Path
from langchain_community.document_loaders import DirectoryLoader, TextLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_openai import OpenAIEmbeddings
from langchain_community.vectorstores import Chroma

# 1. ê²½ë¡œ ì„¤ì • (ì ˆëŒ€ ê²½ë¡œ)
current_dir = Path(__file__).parent.absolute()
data_dir = current_dir / "university_data"
db_dir = current_dir / "university_db"

print(f"ğŸ” ë°ì´í„° ì½ëŠ” ì¤‘: {data_dir}")

# 2. ë°ì´í„° ë¡œë“œ
loader = DirectoryLoader(str(data_dir), glob="**/*.txt", loader_cls=TextLoader, loader_kwargs={'encoding': 'utf-8'})
documents = loader.load()

if not documents:
    print("âŒ í•™ìŠµí•  ì„œë¥˜ê°€ ì—†ìŠµë‹ˆë‹¤. university_data í´ë”ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
else:
    # 3. í…ìŠ¤íŠ¸ ë¶„í•  (ì²­í‚¹)
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=800, chunk_overlap=80)
    texts = text_splitter.split_documents(documents)

    # 4. ì„ë² ë”© ë° ë²¡í„° DB ì €ì¥
    embeddings = OpenAIEmbeddings()
    vector_db = Chroma.from_documents(
        documents=texts, 
        embedding=embeddings, 
        persist_directory=str(db_dir)
    )
    print(f"âœ… í•™ìŠµ ì™„ë£Œ! {len(texts)}ê°œì˜ ì§€ì‹ ì¡°ê°ì´ '{db_dir.name}'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")