import sys
import os

# SQLite ë²„ì „ íŒ¨ì¹˜ (Render ë°°í¬ í˜¸í™˜ì„±)
try:
    import pysqlite3  # type: ignore
    sys.modules['sqlite3'] = pysqlite3
except ImportError:
    pass

from dotenv import load_dotenv
load_dotenv()

# API í‚¤ ê²€ì¦
if not os.getenv("OPENAI_API_KEY"):
    print("âŒ OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    sys.exit(0)

# ğŸ‘‡ ì´ ì•„ë˜ë¶€í„° ë‹¤ë¥¸ import ì‘ì„±

# =========================
# ë‚˜ë¨¸ì§€ import
# =========================
from pathlib import Path
from langchain_community.document_loaders import DirectoryLoader, TextLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_openai import OpenAIEmbeddings
from langchain_community.vectorstores import Chroma

# 1. ê²½ë¡œ ì„¤ì • (ì ˆëŒ€ ê²½ë¡œ)
current_dir = Path(__file__).parent.absolute()
data_dir = current_dir / "university_data"
db_dir = current_dir / "university_db"

# í´ë” ì•ˆì „ì¥ì¹˜: data_dirê°€ ì—†ìœ¼ë©´ ìƒì„±
if not data_dir.exists():
    data_dir.mkdir(parents=True, exist_ok=True)
    print("âš ï¸ ë°ì´í„° í´ë”ê°€ ì—†ì–´ ìƒì„±í–ˆìŠµë‹ˆë‹¤.")

print(f"ğŸ” ë°ì´í„° ì½ëŠ” ì¤‘: {data_dir}")

# 2. ë°ì´í„° ë¡œë“œ (ë¹ˆ ë°ì´í„° ì²˜ë¦¬)
try:
    loader = DirectoryLoader(str(data_dir), glob="**/*.txt", loader_cls=TextLoader, loader_kwargs={'encoding': 'utf-8'})
    documents = loader.load()
except Exception as e:
    print(f"âš ï¸ ë°ì´í„° ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
    documents = []

if not documents:
    print("âš ï¸ í•™ìŠµí•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. DB ìƒì„±ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
    sys.exit(0)
else:
    # 3. í…ìŠ¤íŠ¸ ë¶„í•  (ì²­í‚¹)
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=800, chunk_overlap=80)
    texts = text_splitter.split_documents(documents)

    # 4. ì„ë² ë”© ë° ë²¡í„° DB ì €ì¥
    embeddings = OpenAIEmbeddings()
    vector_db = Chroma.from_documents(
        documents=texts, 
        embedding=embeddings, 
        persist_directory=str(db_dir)
    )
    print(f"âœ… í•™ìŠµ ì™„ë£Œ! {len(texts)}ê°œì˜ ì§€ì‹ ì¡°ê°ì´ '{db_dir.name}'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
