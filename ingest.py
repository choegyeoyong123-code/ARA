import sys
import os

# SQLite λ²„μ „ ν¨μΉ (Render λ°°ν¬ νΈν™μ„±)
try:
    import pysqlite3
    sys.modules['sqlite3'] = pysqlite3
except ImportError:
    pass

from dotenv import load_dotenv
load_dotenv()

# π‘‡ μ΄ μ•„λλ¶€ν„° λ‹¤λ¥Έ import μ‘μ„±

# =========================
# λ‚λ¨Έμ§€ import
# =========================
from pathlib import Path
from langchain_community.document_loaders import DirectoryLoader, TextLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_openai import OpenAIEmbeddings
from langchain_community.vectorstores import Chroma

# 1. κ²½λ΅ μ„¤μ • (μ λ€ κ²½λ΅)
current_dir = Path(__file__).parent.absolute()
data_dir = current_dir / "university_data"
db_dir = current_dir / "university_db"

print(f"π” λ°μ΄ν„° μ½λ” μ¤‘: {data_dir}")

# 2. λ°μ΄ν„° λ΅λ“
loader = DirectoryLoader(str(data_dir), glob="**/*.txt", loader_cls=TextLoader, loader_kwargs={'encoding': 'utf-8'})
documents = loader.load()

if not documents:
    print("β ν•™μµν•  μ„λ¥κ°€ μ—†μµλ‹λ‹¤. university_data ν΄λ”λ¥Ό ν™•μΈν•μ„Έμ”.")
else:
    # 3. ν…μ¤νΈ λ¶„ν•  (μ²­ν‚Ή)
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=800, chunk_overlap=80)
    texts = text_splitter.split_documents(documents)

    # 4. μ„λ² λ”© λ° λ²΅ν„° DB μ €μ¥
    embeddings = OpenAIEmbeddings()
    vector_db = Chroma.from_documents(
        documents=texts, 
        embedding=embeddings, 
        persist_directory=str(db_dir)
    )
    print(f"β… ν•™μµ μ™„λ£! {len(texts)}κ°μ μ§€μ‹ μ΅°κ°μ΄ '{db_dir.name}'μ— μ €μ¥λμ—μµλ‹λ‹¤.")
