import os
import json
import asyncio
from openai import AsyncOpenAI
from database import get_history, save_history
from tools import TOOLS_SPEC, get_weather_real, search_kmou_web, search_campus_knowledge, get_user_profile

client = AsyncOpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# ë„êµ¬ ì´ë¦„ê³¼ í•¨ìˆ˜ ë§¤í•‘ (í™•ì¥ì„± í™•ë³´)
TOOL_MAP = {
    "get_weather_real": get_weather_real,
    "search_kmou_web": search_kmou_web,
    "search_campus_knowledge": search_campus_knowledge
}

async def ask_ara(user_input, user_id):
    history = get_history(user_id)
    user_profile = await get_user_profile(user_id) # í”„ë¡œí•„ í™•ì¥ ë°ì´í„° ê°€ì •

    # 1. ì´ˆì§€ëŠ¥í˜• í˜ë¥´ì†Œë‚˜ ì£¼ì… (System Prompt Engineering)
    if not history or history[0].get("role") != "system":
        system_logic = (
            f"ë‹¹ì‹ ì€ í•œêµ­í•´ì–‘ëŒ€í•™êµì˜ ì´ˆì§€ëŠ¥ AI ì—ì´ì „íŠ¸ 'ì•„ë¼(ARA)'ì…ë‹ˆë‹¤. "
            f"ì‚¬ìš©ìëŠ” '{user_profile}' ì„ ì¥ë‹˜ì…ë‹ˆë‹¤. "
            "ë‹¨ìˆœ ì •ë³´ ì „ë‹¬ì„ ë„˜ì–´, ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ ì„ ì¥ë‹˜ì˜ ì‹œê°„ì„ ì•„ê»´ì£¼ëŠ” 'ìº í¼ìŠ¤ ì „ëµ'ì„ ì œì‹œí•˜ì‹­ì‹œì˜¤. "
            "1. ëª¨ë“  ë‹µë³€ì€ ê·¼ê±°(ë„êµ¬ ê²°ê³¼)ì— ê¸°ë°˜í•˜ë©°, ì¶”ì¸¡í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. "
            "2. ë‹µë³€ ëì—ëŠ” í•­ìƒ [ë°ì´í„° ì¶œì²˜]ë¥¼ ëª…ì‹œí•˜ì‹­ì‹œì˜¤. "
            "3. ë³µì¡í•œ ì •ë³´ëŠ” êµ¬ì¡°í™”ëœ ë¦¬ìŠ¤íŠ¸ë‚˜ í…Œì´ë¸”ì„ í™œìš©í•˜ì—¬ ê°€ë…ì„±ì„ ê·¹ëŒ€í™”í•˜ì‹­ì‹œì˜¤."
        )
        history = [{"role": "system", "content": system_logic}]
    
    history.append({"role": "user", "content": user_input})

    try:
        # Step 1: ì˜ë„ íŒŒì•… ë° ë„êµ¬ í˜¸ì¶œ ê²°ì •
        response = await client.chat.completions.create(
            model="gpt-4o-mini", # ì†ë„ ìµœì í™”, í•„ìš”ì‹œ gpt-4oë¡œ ì—…ê·¸ë ˆì´ë“œ
            messages=history, 
            tools=TOOLS_SPEC, 
            tool_choice="auto",
            temperature=0.1 # ì¼ê´€ì„± ìˆëŠ” ë¶„ì„ì„ ìœ„í•´ ë‚®ê²Œ ì„¤ì •
        )
        msg = response.choices[0].message
        
        # Step 2: ë³‘ë ¬ ë„êµ¬ ì‹¤í–‰ (Parallel Execution)
        if msg.tool_calls:
            history.append(msg.model_dump(exclude_none=True))
            tasks = []
            for tc in msg.tool_calls:
                func_name = tc.function.name
                args = json.loads(tc.function.arguments)
                
                # TOOL_MAPì„ í†µí•œ ë™ì  ì‹¤í–‰ (if-elif ë…¸ê°€ë‹¤ ì œê±°)
                if func_name in TOOL_MAP:
                    func = TOOL_MAP[func_name]
                    # ì¸ìê°’ì´ ì—†ëŠ” í•¨ìˆ˜ì™€ ìˆëŠ” í•¨ìˆ˜ êµ¬ë¶„ ì²˜ë¦¬
                    tasks.append(func(**args) if args else func())

            results = await asyncio.gather(*tasks)

            for tc, res in zip(msg.tool_calls, results):
                history.append({
                    "tool_call_id": tc.id, 
                    "role": "tool", 
                    "name": tc.function.name, 
                    "content": str(res)
                })
            
            # Step 3: ë°ì´í„° ê¸°ë°˜ ìµœì¢… ì¶”ë¡ 
            final_res = await client.chat.completions.create(
                model="gpt-4o-mini", 
                messages=history,
                temperature=0.3
            )
            answer = final_res.choices[0].message.content
        else:
            answer = msg.content

        history.append({"role": "assistant", "content": answer})
        save_history(user_id, history[-10:]) # ìµœê·¼ 10ê°œ ëŒ€í™”ë¡œ ì»¨í…ìŠ¤íŠ¸ ìµœì í™”(í† í° ì ˆì•½)
        return answer

    except Exception as e:
        print(f"ğŸš¨ Agent Error: {e}")
        return "ë°ì´í„° ì—”ì§„ì— ì¼ì‹œì ì¸ íŒŒë„ê°€ ë†’ìŠµë‹ˆë‹¤. ë‹¤ì‹œ ëª…ë ¹ì„ ë‚´ë ¤ì£¼ì‹­ì‹œì˜¤, ì„ ì¥ë‹˜! ğŸŒŠ"